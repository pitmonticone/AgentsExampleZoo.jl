var documenterSearchIndex = {"docs":
[{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/hk.jl\"","category":"page"},{"location":"examples/hk/#Hegselmann-Krause-opinion-dynamics","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"This example showcases","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"How to do synchronous updating of Agent properties (also know as Synchronous update schedule). In a Synchronous update schedule changes made to an agent are not seen by other agents until the next step, see also Wilensky 2015, p.286).\nHow to terminate the system evolution on demand according to a boolean function.\nHow to terminate the system evolution according to what happened on the previous step.","category":"page"},{"location":"examples/hk/#Model-overview","page":"Hegselmann-Krause opinion dynamics","title":"Model overview","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"This is an implementation of a simple version of the Hegselmann and Krause (2002) model. It is a model of opinion formation with the question: which parameters' values lead to consensus, polarization or fragmentation? It models interacting groups of agents (as opposed to interacting pairs, typical in the literature) in which it is assumed that if an agent disagrees too much with the opinion of a source of influence, the source can no longer influence the agent's opinion. There is then a \"bound of confidence\". The model shows that the systemic configuration is heavily dependent on this parameter's value.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"The model has the following components:","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"A set of n Agents with opinions xᵢ in the range [0,1] as attribute\nA parameter ϵ called \"bound\" in (0, 0.3]\nThe update rule: at each step every agent adopts the mean of the opinions which are within the confidence bound ( |xᵢ - xⱼ| ≤ ϵ).","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"It is also available from the Models module as Models.hk.","category":"page"},{"location":"examples/hk/#Core-structures","page":"Hegselmann-Krause opinion dynamics","title":"Core structures","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"We start by defining the Agent type and initializing the model. The Agent type has two fields so that we can implement the synchronous update.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"using Agents\nusing Statistics: mean\n\nmutable struct HKAgent <: AbstractAgent\n    id::Int\n    old_opinion::Float64\n    new_opinion::Float64\n    previous_opinion::Float64\nend","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"There is a reason the agent has three fields that are \"the same\". The old_opinion is used for the synchronous agent update, since we require access to a property's value at the start of the step and the end of the step. The previous_opinion is the opinion of the agent in the previous step, as the model termination requires access to a property's value at the end of the previous step, and the end of the current step.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"We could, alternatively, make the three opinions a single field with vector value.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function hk_model(; numagents = 100, ϵ = 0.2)\n    model = ABM(HKAgent, scheduler = Schedulers.fastest, properties = Dict(:ϵ => ϵ))\n    for i in 1:numagents\n        o = rand(model.rng)\n        add_agent!(model, o, o, -1)\n    end\n    return model\nend\n\nmodel = hk_model()","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Add some helper functions for the update rule. As there is a filter in the rule we implement it outside the agent_step! method. Notice that the filter is applied to the :old_opinion field.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function boundfilter(agent, model)\n    filter(\n        j -> abs(agent.old_opinion - j) < model.ϵ,\n        [a.old_opinion for a in allagents(model)],\n    )\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Now we implement the agent_step!","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function agent_step!(agent, model)\n    agent.previous_opinion = agent.old_opinion\n    agent.new_opinion = mean(boundfilter(agent, model))\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"and model_step!","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function model_step!(model)\n    for a in allagents(model)\n        a.old_opinion = a.new_opinion\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"From this implementation we see that to implement synchronous scheduling we define an Agent type with old and new fields for attributes that are changed via the synchronous update. In agent_step! we use the old field then, after updating all the agents new fields, we use the model_step! to update the model for the next iteration.","category":"page"},{"location":"examples/hk/#Running-the-model","page":"Hegselmann-Krause opinion dynamics","title":"Running the model","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"The parameter of interest is now :new_opinion, so we assign it to variable adata and pass it to the run! method to be collected in a DataFrame.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"In addition, we want to run the model only until all agents have converged to an opinion. From the documentation of step! one can see that instead of specifying the amount of steps we can specify a function instead.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function terminate(model, s)\n    if any(\n        !isapprox(a.previous_opinion, a.new_opinion; rtol = 1e-12)\n        for a in allagents(model)\n    )\n        return false\n    else\n        return true\n    end\nend\n\nAgents.step!(model, agent_step!, model_step!, terminate)\nmodel[1]","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Alright, let's wrap everything in a function and do some data collection using run!.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function model_run(; kwargs...)\n    model = hk_model(; kwargs...)\n    agent_data, _ = run!(model, agent_step!, model_step!, terminate; adata = [:new_opinion])\n    return agent_data\nend\n\ndata = model_run(numagents = 100)\ndata[(end-19):end, :]","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Notice that here we didn't speciy when to collect data, so this is done at every step. Instead, we could collect data only at the final step, by re-using the same function for the when argument:","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"model = hk_model()\nagent_data, _ = run!(\n    model,\n    agent_step!,\n    model_step!,\n    terminate;\n    adata = [:new_opinion],\n    when = terminate,\n)\nagent_data","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Finally we run three scenarios, collect the data and plot it.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"using DataFrames, CairoMakie\nCairoMakie.activate!() # hide\nusing Random # hide\nRandom.seed!(42) # hide\n\nconst cmap = cgrad(:lightrainbow)\nplotsim(ax, data) =\n    for grp in groupby(data, :id)\n        lines!(ax, grp.step, grp.new_opinion, color = cmap[grp.id[1]/100])\n    end\n\neps = [0.05, 0.15, 0.3]\nfigure = Figure(resolution = (600, 600))\nfor (i, e) in enumerate(eps)\n    ax = figure[i, 1] = Axis(figure; title = \"epsilon = $e\")\n    e_data = model_run(ϵ = e)\n    plotsim(ax, e_data)\nend\nfigure","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/growing_bacteria.jl\"","category":"page"},{"location":"examples/growing_bacteria/#Bacterial-Growth","page":"Bacterial Growth","title":"Bacterial Growth","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../bacteria.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"Bacterial colonies are a prime example for growing active matter, where systems are driven out of equilibrium by proliferation. This model is a simplified version of unpublished work by Yoav G. Pollack and Philip Bittihn; similar models can be found in literature. Here, a bacterium is modelled by two soft disk \"nodes\" linked by a spring, whose rest length grows with a constant growth rate. When it has reached its full extension, the cell divides into two daughter cells with the same orientation.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"This example is a showcase of a complex continuous system. Agents will be splitting into more agents, thus having agent generation in continuous space. The model also uses advanced agent movement in continuous space, where a specialized \"move_agent\" function is created. Advanced plotting is also done, since each agent is a specialized shape. It is also available from the Models module as Models.growing_bacteria.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"using Agents, LinearAlgebra\nusing Random # hide\n\nmutable struct SimpleCell <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    length::Float64\n    orientation::Float64\n    growthprog::Float64\n    growthrate::Float64\n\n    # node positions/forces\n    p1::NTuple{2,Float64}\n    p2::NTuple{2,Float64}\n    f1::NTuple{2,Float64}\n    f2::NTuple{2,Float64}\nend\n\nfunction SimpleCell(id, pos, l, φ, g, γ)\n    a = SimpleCell(id, pos, l, φ, g, γ, (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0))\n    update_nodes!(a)\n    return a\nend","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"In this model, the agents have to store their state in two redundant ways: the cell coordinates (position, length, orientation) are required for the equations of motion, while the positions of the disk-shaped nodes are necessary for calculating mechanical forces between cells. To transform from one set of coordinates to the other, we need to write a function","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"function update_nodes!(a::SimpleCell)\n    offset = 0.5 * a.length .* unitvector(a.orientation)\n    a.p1 = a.pos .+ offset\n    a.p2 = a.pos .- offset\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"Some geometry convenience functions","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"unitvector(φ) = reverse(sincos(φ))\ncross2D(a, b) = a[1] * b[2] - a[2] * b[1]\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Stepping-functions","page":"Bacterial Growth","title":"Stepping functions","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"function model_step!(model)\n    extent = model.space.extent\n    for a in allagents(model)\n        if a.growthprog ≥ 1\n            # When a cell has matured, it divides into two daughter cells on the\n            # positions of its nodes.\n            add_agent!(a.p1, model, 0.0, a.orientation, 0.0, 0.1 * rand(model.rng) + 0.05)\n            add_agent!(a.p2, model, 0.0, a.orientation, 0.0, 0.1 * rand(model.rng) + 0.05)\n            kill_agent!(a, model)\n        else\n            # The rest lengh of the internal spring grows with time. This causes\n            # the nodes to physically separate.\n            uv = unitvector(a.orientation)\n            internalforce = model.hardness * (a.length - a.growthprog) .* uv\n            a.f1 = -1 .* internalforce\n            a.f2 = internalforce\n        end\n    end\n    # Bacteria can interact with more than on other cell at the same time, therefore,\n    # we need to specify the option `:all` in `interacting_pairs`\n    for (a1, a2) in interacting_pairs(model, 2.0, :all)\n        interact!(a1, a2, model)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"Here we use a custom move_agent! function, because the agents have several moving parts. Notice that the first derivatives of all degrees of freedom is directly proportional to the force applied to them. This overdamped approximation is valid for small length scales, where viscous forces dominate over inertia.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"function agent_step!(agent::SimpleCell, model::ABM)\n    fsym, compression, torque = transform_forces(agent)\n    direction =  model.dt * model.mobility .* fsym\n    walk!(agent, direction, model)\n    agent.length += model.dt * model.mobility .* compression\n    agent.orientation += model.dt * model.mobility .* torque\n    agent.growthprog += model.dt * agent.growthrate\n    update_nodes!(agent)\n    return agent.pos\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Helper-functions","page":"Bacterial Growth","title":"Helper functions","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"function interact!(a1::SimpleCell, a2::SimpleCell, model)\n    n11 = noderepulsion(a1.p1, a2.p1, model)\n    n12 = noderepulsion(a1.p1, a2.p2, model)\n    n21 = noderepulsion(a1.p2, a2.p1, model)\n    n22 = noderepulsion(a1.p2, a2.p2, model)\n    a1.f1 = @. a1.f1 + (n11 + n12)\n    a1.f2 = @. a1.f2 + (n21 + n22)\n    a2.f1 = @. a2.f1 - (n11 + n21)\n    a2.f2 = @. a2.f2 - (n12 + n22)\nend\n\nfunction noderepulsion(p1::NTuple{2,Float64}, p2::NTuple{2,Float64}, model::ABM)\n    delta = p1 .- p2\n    distance = norm(delta)\n    if distance ≤ 1\n        uv = delta ./ distance\n        return (model.hardness * (1 - distance)) .* uv\n    end\n    return (0, 0)\nend\n\nfunction transform_forces(agent::SimpleCell)\n    # symmetric forces (CM movement)\n    fsym = agent.f1 .+ agent.f2\n    # antisymmetric forces (compression, torque)\n    fasym = agent.f1 .- agent.f2\n    uv = unitvector(agent.orientation)\n    compression = dot(uv, fasym)\n    torque = 0.5 * cross2D(uv, fasym)\n    return fsym, compression, torque\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Animating-bacterial-growth","page":"Bacterial Growth","title":"Animating bacterial growth","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"Okay, we can now initialize a model and see what it does.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"space = ContinuousSpace((14, 9), 1.0; periodic = false)\nmodel = ABM(\n    SimpleCell,\n    space,\n    properties = Dict(:dt => 0.005, :hardness => 1e2, :mobility => 1.0),\n    rng = MersenneTwister(1680)\n)","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"Let's start with just two agents.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"add_agent!((6.5, 4.0), model, 0.0, 0.3, 0.0, 0.1)\nadd_agent!((7.5, 4.0), model, 0.0, 0.0, 0.0, 0.1)\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"The model has several parameters, and some of them are of interest. We could e.g. define","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"adata = [:pos, :length, :orientation, :growthprog, :p1, :p2, :f1, :f2]\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"and then run! the model. But we'll animate the model directly.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"Here we once again use the huge flexibility provided by plotabm to plot the bacteria cells. We define a function that creates a custom Shape based on the agent:","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"using InteractiveDynamics\nusing CairoMakie # choose plotting backend\nCairoMakie.activate!() # hide\n\nfunction cassini_oval(agent)\n    t = LinRange(0, 2π, 50)\n    a = agent.growthprog\n    b = 1\n    m = @. 2 * sqrt((b^4 - a^4) + a^4 * cos(2 * t)^2) + 2 * a^2 * cos(2 * t)\n    C = sqrt.(m / 2)\n\n    x = C .* cos.(t)\n    y = C .* sin.(t)\n\n    uv = reverse(sincos(agent.orientation))\n    θ = atan(uv[2], uv[1])\n    R = [cos(θ) -sin(θ); sin(θ) cos(θ)]\n\n    bacteria = R * permutedims([x y])\n    coords = [Point2f0(x, y) for (x, y) in zip(bacteria[1, :], bacteria[2, :])]\n    scale(Polygon(coords), 0.5)\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"set up some nice colors","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"bacteria_color(b) = CairoMakie.RGBf0(b.id * 3.14 % 1, 0.2, 0.2)\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"and proceed with the animation","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"abm_video(\n    \"bacteria.mp4\", model, agent_step!, model_step!;\n    am = cassini_oval, ac = bacteria_color,\n    spf = 50, framerate = 30, frames = 200,\n    title = \"Growing bacteria\"\n)","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacterial Growth","title":"Bacterial Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../bacteria.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/sugarscape.jl\"","category":"page"},{"location":"examples/sugarscape/#Sugarscape","page":"Sugarscape","title":"Sugarscape","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Growing Artificial Societies","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sugarvis.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"(Descriptions below are from this page)","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"\"Growing Artificial Societies\" (Epstein & Axtell 1996) is a reference book for scientists interested in agent-based modelling and computer simulation. It represents one of the most paradigmatic and fascinating examples of the so-called generative approach to social science (Epstein 1999). In their book, Epstein & Axtell (1996) present a computational model where a heterogeneous population of autonomous agents compete for renewable resources that are unequally distributed over a 2-dimensional environment. Agents in the model are autonomous in that they are not governed by any central authority and they are heterogeneous in that they differ in their genetic attributes and their initial environmental endowments (e.g. their initial location and wealth). The model grows in complexity through the different chapters of the book as the agents are given the ability to engage in new activities such as sex, cultural exchange, trade, combat, disease transmission, etc. The core of Sugarscape has provided the basis for various extensions to study e.g. norm formation through cultural diffusion (Flentge et al. 2001) and the emergence of communication and cooperation in artificial societies (Buzing et al. 2005). Here we analyse the model described in the second chapter of Epstein & Axtell's (1996) book within the Markov chain framework.","category":"page"},{"location":"examples/sugarscape/#Rules-of-sugarscape","page":"Sugarscape","title":"Rules of sugarscape","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The first model that Epstein & Axtell (1996) present comprises a finite population of agents who live in an environment. The environment is represented by a two-dimensional grid which contains sugar in some of its cells, hence the name Sugarscape. Agents' role in this first model consists in wandering around the Sugarscape harvesting the greatest amount of sugar they can find.","category":"page"},{"location":"examples/sugarscape/#Environment","page":"Sugarscape","title":"Environment","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The environment is a 50×50 grid that wraps around forming a torus. Grid positions have both a sugar level and a sugar capacity c. A cell's sugar level is the number of units of sugar in the cell (potentially none), and its sugar capacity c is the maximum value the sugar level can take on that cell. Sugar capacity is fixed for each individual cell and may be different for different cells. The spatial distribution of sugar capacities depicts a sugar topography consisting of two peaks (with sugar capacity c = 4) separated by a valley, and surrounded by a desert region of sugarless cells (see Figure 1). Note, however, that the grid wraps around in both directions.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The Sugarscape obbeys the following rule:","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Sugarscape growback rule Galpha: At each position, sugar grows back at a rate of alpha units per time-step up to the cell's capacity c.","category":"page"},{"location":"examples/sugarscape/#Agents","page":"Sugarscape","title":"Agents","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Every agent is endowed with individual (life-long) characteristics that condition her skills and capacities to survive in the Sugarscape. These individual attributes are:","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"A vision v, which is the maximum number of positions the agent can see in each of","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"the four principal lattice directions: north, south, east and west.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"A metabolic rate m, which represents the units of sugar the agent burns per time-step.\nA maximum age max-age, which is the maximum number of time-steps the agent can live.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Agents also have the capacity to accumulate sugar wealth w. An agent's sugar wealth is incremented at the end of each time-step by the sugar collected and decremented by the agent's metabolic rate. Two agents are not allowed to occupy the same position in the grid.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The agents' behaviour is determined by the following two rules:","category":"page"},{"location":"examples/sugarscape/#Agent-movement-rule-*M*:","page":"Sugarscape","title":"Agent movement rule M:","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Consider the set of unoccupied positions within your vision (including the one you are standing on), identify the one(s) with the greatest amount of sugar, select the nearest one (randomly if there is more than one), move there and collect all the sugar in it. At this point, the agent's accumulated sugar wealth is incremented by the sugar collected and decremented by the agent's metabolic rate m. If at this moment the agent's sugar wealth is not greater than zero, then the agent dies.","category":"page"},{"location":"examples/sugarscape/#Agent-replacement-rule-*R*:","page":"Sugarscape","title":"Agent replacement rule R:","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Whenever an agent dies it is replaced by a new agent of age 0 placed on a randomly chosen unoccupied position, having random attributes v, m and max-age, and random initial wealth w0. All random numbers are drawn from uniform distributions with ranges specified in Table 1 below.","category":"page"},{"location":"examples/sugarscape/#Scheduling-of-events","page":"Sugarscape","title":"Scheduling of events","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Scheduling is determined by the order in which the different rules G, M and R are fired in the model. Environmental rule G comes first, followed by agent rule M (which is executed by all agents in random order) and finally agent rule R is executed (again, by all agents in random order).","category":"page"},{"location":"examples/sugarscape/#Parameterisation","page":"Sugarscape","title":"Parameterisation","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Our analysis corresponds to a model used by Epstein & Axtell (1996, pg. 33) to study the emergent wealth distribution in the agent population. This model is parameterised as indicated in Table 1 below (where U[a,b] denotes a uniform distribution with range [a,b]).","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Initially, each position of the Sugarscape contains a sugar level equal to its sugar capacity c, and the 250 agents are created at a random unoccupied initial location and with random attributes (using the uniform distributions indicated in Table 1).","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Table 1","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Parameter Value\nLattice length L 50\nNumber of sugar peaks 2\nGrowth rate alpha 1\nNumber of agents N 250\nAgents' initial wealth w0 distribution U[5,25]\nAgents' metabolic rate m distribution U[1,4]\nAgents' vision v distribution U[1,6]\nAgents' maximum age max-age distribution U[60,100]","category":"page"},{"location":"examples/sugarscape/#Creating-the-ABM","page":"Sugarscape","title":"Creating the ABM","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using Agents, Random\n\nmutable struct SugarSeeker <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    vision::Int\n    metabolic_rate::Int\n    age::Int\n    max_age::Int\n    wealth::Int\nend","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Functions distances and sugar_caps produce a matrix for the distribution of sugar capacities.\"","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"function distances(pos, sugar_peaks, max_sugar)\n    all_dists = Array{Int,1}(undef, length(sugar_peaks))\n    for (ind, peak) in enumerate(sugar_peaks)\n        d = round(Int, sqrt(sum((pos .- peak) .^ 2)))\n        all_dists[ind] = d\n    end\n    return minimum(all_dists)\nend\n\nfunction sugar_caps(dims, sugar_peaks, max_sugar, dia = 4)\n    sugar_capacities = zeros(Int, dims)\n    for i in 1:dims[1], j in 1:dims[2]\n        sugar_capacities[i, j] = distances((i, j), sugar_peaks, max_sugar)\n    end\n    for i in 1:dims[1]\n        for j in 1:dims[2]\n            sugar_capacities[i, j] = max(0, max_sugar - (sugar_capacities[i, j] ÷ dia))\n        end\n    end\n    return sugar_capacities\nend\n\n\"Create a sugarscape ABM\"\nfunction sugarscape(;\n    dims = (50, 50),\n    sugar_peaks = ((10, 40), (40, 10)),\n    growth_rate = 1,\n    N = 250,\n    w0_dist = (5, 25),\n    metabolic_rate_dist = (1, 4),\n    vision_dist = (1, 6),\n    max_age_dist = (60, 100),\n    max_sugar = 4,\n    seed = 42\n)\n    sugar_capacities = sugar_caps(dims, sugar_peaks, max_sugar, 6)\n    sugar_values = deepcopy(sugar_capacities)\n    space = GridSpace(dims)\n    properties = Dict(\n        :growth_rate => growth_rate,\n        :N => N,\n        :w0_dist => w0_dist,\n        :metabolic_rate_dist => metabolic_rate_dist,\n        :vision_dist => vision_dist,\n        :max_age_dist => max_age_dist,\n        :sugar_values => sugar_values,\n        :sugar_capacities => sugar_capacities,\n    )\n    model = AgentBasedModel(\n        SugarSeeker,\n        space,\n        scheduler = Schedulers.randomly,\n        properties = properties,\n        rng = MersenneTwister(seed)\n    )\n    for ag in 1:N\n        add_agent_single!(\n            model,\n            rand(model.rng, vision_dist[1]:vision_dist[2]),\n            rand(model.rng, metabolic_rate_dist[1]:metabolic_rate_dist[2]),\n            0,\n            rand(model.rng, max_age_dist[1]:max_age_dist[2]),\n            rand(model.rng, w0_dist[1]:w0_dist[2]),\n        )\n    end\n    return model\nend\n\nmodel = sugarscape()","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Let's plot the spatial distribution of sugar capacities in the Sugarscape.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using CairoMakie\nCairoMakie.activate!() # hide\n\nfig = Figure(resolution = (600, 600))\nax, hm = heatmap(fig[1,1], model.sugar_capacities; colormap=cgrad(:thermal))\nColorbar(fig[1, 2], hm, width = 20)\nfig","category":"page"},{"location":"examples/sugarscape/#Defining-stepping-functions","page":"Sugarscape","title":"Defining stepping functions","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Now we define the stepping functions that handle the time evolution of the model","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"function model_step!(model)\n    # At each position, sugar grows back at a rate of $\\alpha$ units\n    # per time-step up to the cell's capacity c.\n    togrow = findall(\n        x -> model.sugar_values[x] < model.sugar_capacities[x],\n        1:length(positions(model)),\n    )\n    model.sugar_values[togrow] .+= model.growth_rate\nend\n\nfunction movement!(agent, model)\n    newsite = agent.pos\n    # find all unoccupied position within vision\n    neighbors = nearby_positions(agent.pos, model, agent.vision)\n    empty = collect(empty_positions(model))\n    if length(empty) > 0\n        # identify the one(s) with greatest amount of sugar\n        available_sugar = (model.sugar_values[x,y] for (x, y) in empty)\n        maxsugar = maximum(available_sugar)\n        if maxsugar > 0\n            sugary_sites_inds = findall(x -> x == maxsugar, collect(available_sugar))\n            sugary_sites = empty[sugary_sites_inds]\n            # select the nearest one (randomly if more than one)\n            for dia in 1:(agent.vision)\n                np = nearby_positions(agent.pos, model, dia)\n                suitable = intersect(np, sugary_sites)\n                if length(suitable) > 0\n                    newsite = rand(model.rng, suitable)\n                    break\n                end\n            end\n            # move there and collect all the sugar in it\n            newsite != agent.pos && move_agent!(agent, newsite, model)\n        end\n    end\n    # update wealth (collected - consumed)\n    agent.wealth += (model.sugar_values[newsite...] - agent.metabolic_rate)\n    model.sugar_values[newsite...] = 0\n    # age\n    agent.age += 1\nend\n\nfunction replacement!(agent, model)\n    # If the agent's sugar wealth become zero or less, it dies\n    if agent.wealth <= 0 || agent.age >= agent.max_age\n        kill_agent!(agent, model)\n        # Whenever an agent dies, a young one is added to a random pos.\n        # New agent has random attributes\n        add_agent_single!(\n            model,\n            rand(model.rng, model.vision_dist[1]:model.vision_dist[2]),\n            rand(model.rng, model.metabolic_rate_dist[1]:model.metabolic_rate_dist[2]),\n            0,\n            rand(model.rng, model.max_age_dist[1]:model.max_age_dist[2]),\n            rand(model.rng, model.w0_dist[1]:model.w0_dist[2]),\n        )\n    end\nend\n\nfunction agent_step!(agent, model)\n    movement!(agent, model)\n    replacement!(agent, model)\nend","category":"page"},{"location":"examples/sugarscape/#Plotting-and-Animating","page":"Sugarscape","title":"Plotting & Animating","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We can plot the ABM and the sugar distribution side by side using abm_plot and standard Makie.jl commands like so","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using InteractiveDynamics\n\nmodel = sugarscape()\nfig, abmstepper = abm_plot(model; resolution = (800, 600))\nax, hm = heatmap(fig[1,2], model.sugar_values; colormap=cgrad(:thermal), colorrange=(0,4))\nax.aspect = AxisAspect(1) # equal aspect ratio for heatmap\nColorbar(fig[1, 3], hm, width = 15, tellheight=false)\nrowsize!(fig.layout, 1, ax.scene.px_area[].widths[2]) # Colorbar height = axis height\nfig","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"To animate them both however, we will use the approach Makie.jl suggests for animations, which is based on Observables. We start similarly with a call to abm_plot, but now make the plotted heatmap an obsrvable","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"fig, abmstepper = abm_plot(model; resolution = (800, 600))\nobs_heat = Observable(model.sugar_values)\nax, hm = heatmap(fig[1,2], obs_heat; colormap=cgrad(:thermal), colorrange=(0,4))\nax.aspect = AxisAspect(1) # equal aspect ratio for heatmap\nColorbar(fig[1, 3], hm, width = 15, tellheight=false)\nrowsize!(fig.layout, 1, ax.scene.px_area[].widths[2]) # Colorbar height = axis height","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"and also add a title for good measure","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"s = Observable(0) # counter of current step, also observable\nt = lift(x -> \"Sugarscape, step = $x\", s)\nsupertitle = Label(fig[0, :], t, textsize = 24, halign = :left)\nfig","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We animate the evolution of both the ABM and the sugar distribution using the following simple loop involving the abm stepper","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"record(fig, \"sugarvis.mp4\"; framerate = 3) do io\n    for j in 0:50 # = total number of frames\n        recordframe!(io) # save current state\n        # This updates the abm plot:\n        Agents.step!(abmstepper, model, agent_step!, model_step!, 1)\n        # This updates the heatmap:\n        obs_heat[] = model.sugar_values\n        # This updates the title:\n        s[] = s[] + 1\n    end\nend","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sugarvis.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/#Distribution-of-wealth-across-individuals","page":"Sugarscape","title":"Distribution of wealth across individuals","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"First we produce some data that include the wealth","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"model2 = sugarscape()\nadata, _ = run!(model2, agent_step!, model_step!, 20, adata = [:wealth])\nadata[1:10,:]","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"And now we animate the evolution of the distribution of wealth","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"figure = Figure(resolution = (600, 600))\ntitle_text = Observable(\"Wealth distribution of individuals\\nStep 1\")\nfigure[1, 1] = Label(figure, title_text; textsize=30, tellwidth=false)\nax = figure[2, 1] = Axis(figure; xlabel=\"Wealth\", ylabel=\"Number of agents\")\nhistdata = Observable(adata[adata.step .== 20, :wealth])\nhist!(ax, histdata; bar_position=:step)\nrecord(figure, \"sugarhist.mp4\", 0:20; framerate=3) do i\n    histdata[] = adata[adata.step .== i, :wealth]\n    title_text[] = \"Wealth distribution of individuals, step = $i\"\n    xlims!(ax, (0, max(histdata[]...)))\n    ylims!(ax, (0, 50))\nend\nnothing # hide","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We see that the distribution of wealth shifts from a more or less uniform distribution to a skewed distribution.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sugarhist.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/#References","page":"Sugarscape","title":"References","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"BUZING P, Eiben A & Schut M (2005) Emerging communication and cooperation in evolving agent societies. Journal of Artificial Societies and Social Simulation 8(1)2. http://jasss.soc.surrey.ac.uk/8/1/2.html.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EPSTEIN J M (1999) Agent-Based Computational Models And Generative Social Science. Complexity 4(5), pp. 41-60.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EPSTEIN J M & Axtell R L (1996) Growing Artificial Societies: Social Science from the Bottom Up. The MIT Press.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"FLENTGE F, Polani D & Uthmann T (2001) Modelling the emergence of possession norms using memes. Journal of Artificial Societies and Social Simulation 4(4)3. http://jasss.soc.surrey.ac.uk/4/4/3.html.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/runners.jl\"","category":"page"},{"location":"examples/runners/#Mountain-Runners","page":"Mountain Runners","title":"Mountain Runners","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../runners.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"Let's consider a race to the top of a mountain. Runners have been scattered about a map in some low lying areas and need to find the best path up to the peak.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"We'll use Pathfinding.AStar and a Pathfinding.PenaltyMap to simulate this.","category":"page"},{"location":"examples/runners/#Setup","page":"Mountain Runners","title":"Setup","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"using Agents, Agents.Pathfinding\nusing Random\nusing FileIO # To load images you also need ImageMagick available to your project\n\n@agent Runner GridAgent{2} begin end","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"Our agent, as you can see, is very simple. Just an id and position provided by @agent. The rest of the dynamics of this example will be provided by the model.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"function initialize(map_url; goal = (128, 409), seed = 88)\n    # Load an image file and convert it do a simple representation of height\n    heightmap = floor.(Int, convert.(Float64, load(download(map_url))) * 255)\n    # The space of the model can be obtained directly from the image.\n    # Our example file is (400, 500).\n    space = GridSpace(size(heightmap); periodic = false)\n    # The pathfinder. We use the `MaxDistance` metric since we want the runners\n    # to look for the easiest path to run, not just the most direct.\n    pathfinder = AStar(space; cost_metric = PenaltyMap(heightmap, MaxDistance{2}()))\n    model = ABM(\n        Runner,\n        space;\n        rng = MersenneTwister(seed),\n        properties = Dict(:goal => goal, :pathfinder => pathfinder)\n    )\n    for _ in 1:10\n        # Place runners in the low-lying space in the map.\n        runner = add_agent!((rand(model.rng, 100:350), rand(model.rng, 50:200)), model)\n        # Everyone wants to get to the same place.\n        set_target!(runner, goal, model.pathfinder)\n    end\n    return model\nend","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"The example heightmap we use here is a small region of countryside in Sweden, obtained with the Tangram heightmapper.","category":"page"},{"location":"examples/runners/#Dynamics","page":"Mountain Runners","title":"Dynamics","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"With the pathfinder in place, and all our runners having a goal position set, stepping is now trivial.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"agent_step!(agent, model) = move_along_route!(agent, model, model.pathfinder)","category":"page"},{"location":"examples/runners/#Let's-Race","page":"Mountain Runners","title":"Let's Race","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"Plotting is simple enough. We just need to use the InteractiveDynamics.abm_plot for our runners, and display the heightmap for our reference. A better interface to do this is currently a work in progress.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"We load the sample heightmap","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"map_url =\n    \"https://raw.githubusercontent.com/JuliaDynamics/\" *\n    \"JuliaDynamics/master/videos/agents/runners_heightmap.jpg\"\nmodel = initialize(map_url)","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"and plot","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"static_preplot!(ax, model) = scatter!(ax, model.goal; color = (:red, 50), marker = 'x')\n\nabm_video(\n    \"runners.mp4\",\n    model,\n    agent_step!;\n    resolution = (700, 700),\n    frames = 410,\n    framerate = 45,\n    ac = :black,\n    as = 8,\n    scatterkwargs = (strokecolor = :white, strokewidth = 2),\n    heatarray = model -> penaltymap(model.pathfinder),\n    heatkwargs = (colormap = :terrain,),\n    static_preplot!\n)\nnothing # hide","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../runners.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/predator_prey_fast.jl\"","category":"page"},{"location":"examples/predator_prey_fast/#Predator-prey-dynamics","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"","category":"section"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sheepwolf.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The predator-prey model emulates the population dynamics of predator and prey animals who live in a common ecosystem and compete over limited resources. This model is an agent-based analog to the classic Lotka-Volterra differential equation model. This example illustrates how to develop models with heterogeneous agents (sometimes referred to as a mixed agent based model).","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The environment is a two dimensional grid containing sheep, wolves and grass. In the model, wolves eat sheep and sheep eat grass. Their populations will oscillate over time if the correct balance of resources is achieved. Without this balance however, a population may become extinct. For example, if wolf population becomes too large, they will deplete the sheep and subsequently die of starvation.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"We will begin by loading the required packages and defining three subtypes of AbstractAgent: Sheep, Wolf, and Grass. All three agent types have id and pos properties, which is a requirement for all subtypes of AbstractAgent when they exist upon a GridSpace. Sheep and wolves have identical properties, but different behaviors as explained below. The property energy represents an animals current energy level. If the level drops below zero, the agent will die. Sheep and wolves reproduce asexually in this model, with a probability given by reproduction_prob. The property Δenergy controls how much energy is acquired after consuming a food source.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Grass is a replenishing resource that occupies every position in the grid space. Grass can be consumed only if it is fully_grown. Once the grass has been consumed, it replenishes after a delay specified by the property regrowth_time. The property countdown tracks the delay between being consumed and the regrowth time.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"It is also available from the Models module as Models.predator_prey.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"using Agents, Random\n\nmutable struct SheepWolf <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    type::Symbol # :sheep or :wolf\n    energy::Float64\n    reproduction_prob::Float64\n    Δenergy::Float64\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Simple helper functions","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Sheep(id, pos, energy, repr, Δe) = SheepWolf(id, pos, :sheep, energy, repr, Δe)\nWolf(id, pos, energy, repr, Δe) = SheepWolf(id, pos, :wolf, energy, repr, Δe)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The function initialize_model returns a new model containing sheep, wolves, and grass using a set of pre-defined values (which can be overwritten). The environment is a two dimensional grid space, which enables animals to walk in all directions.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function initialize_model(;\n    n_sheep = 100,\n    n_wolves = 50,\n    dims = (20, 20),\n    regrowth_time = 30,\n    Δenergy_sheep = 4,\n    Δenergy_wolf = 20,\n    sheep_reproduce = 0.04,\n    wolf_reproduce = 0.05,\n    seed = 23182,\n)\n\n    rng = MersenneTwister(seed)\n    space = GridSpace(dims, periodic = false)\n    # Model properties contain the grass as two arrays: whether it is fully grown\n    # and the time to regrow. Also have static parameter `regrowth_time`.\n    # Notice how the properties are a `NamedTuple` to ensure type stability.\n    properties = (\n        fully_grown = falses(dims),\n        countdown = zeros(Int, dims),\n        regrowth_time = regrowth_time,\n    )\n    model = ABM(SheepWolf, space; properties, rng, scheduler = Schedulers.randomly)\n    id = 0\n    for _ in 1:n_sheep\n        id += 1\n        energy = rand(1:(Δenergy_sheep*2)) - 1\n        sheep = Sheep(id, (0, 0), energy, sheep_reproduce, Δenergy_sheep)\n        add_agent!(sheep, model)\n    end\n    for _ in 1:n_wolves\n        id += 1\n        energy = rand(1:(Δenergy_wolf*2)) - 1\n        wolf = Wolf(id, (0, 0), energy, wolf_reproduce, Δenergy_wolf)\n        add_agent!(wolf, model)\n    end\n    for p in positions(model) # random grass initial growth\n        fully_grown = rand(model.rng, Bool)\n        countdown = fully_grown ? regrowth_time : rand(model.rng, 1:regrowth_time) - 1\n        model.countdown[p...] = countdown\n        model.fully_grown[p...] = fully_grown\n    end\n    return model\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The function sheepwolf_step! is dispatched on the sheep and wolves similarly: both lose 1 energy unit by moving to an adjacent position and both consume a food source if available. If their energy level is below zero, they die. Otherwise, they live and reproduces with some probability.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Sheep and wolves move to a random adjacent position with the walk! function.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function sheepwolf_step!(agent::SheepWolf, model)\n    if agent.type == :sheep\n        sheep_step!(agent, model)\n    else # then `agent.type == :wolf`\n        wolf_step!(agent, model)\n    end\nend\n\nfunction sheep_step!(sheep, model)\n    walk!(sheep, rand, model)\n    sheep.energy -= 1\n    sheep_eat!(sheep, model)\n    if sheep.energy < 0\n        kill_agent!(sheep, model)\n        return\n    end\n    if rand(model.rng) <= sheep.reproduction_prob\n        reproduce!(sheep, model)\n    end\nend\n\nfunction wolf_step!(wolf, model)\n    walk!(wolf, rand, model)\n    wolf.energy -= 1\n    agents = collect(agents_in_position(wolf.pos, model))\n    dinner = filter!(x -> x.type == :sheep, agents)\n    wolf_eat!(wolf, dinner, model)\n    if wolf.energy < 0\n        kill_agent!(wolf, model)\n        return\n    end\n    if rand(model.rng) <= wolf.reproduction_prob\n        reproduce!(wolf, model)\n    end\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Sheep and wolves have separate eat! functions. If a sheep eats grass, it will acquire additional energy and the grass will not be available for consumption until regrowth time has elapsed. If a wolf eats a sheep, the sheep dies and the wolf acquires more energy.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function sheep_eat!(sheep, model)\n    if model.fully_grown[sheep.pos...]\n        sheep.energy += sheep.Δenergy\n        model.fully_grown[sheep.pos...] = false\n    end\nend\n\nfunction wolf_eat!(wolf, sheep, model)\n    if !isempty(sheep)\n        dinner = rand(model.rng, sheep)\n        kill_agent!(dinner, model)\n        wolf.energy += wolf.Δenergy\n    end\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Sheep and wolves share a common reproduction method. Reproduction has a cost of 1/2 the current energy level of the parent. The offspring is an exact copy of the parent, with exception of id.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function reproduce!(agent, model)\n    agent.energy /= 2\n    id = nextid(model)\n    offspring = SheepWolf(\n        id,\n        agent.pos,\n        agent.type,\n        agent.energy,\n        agent.reproduction_prob,\n        agent.Δenergy,\n    )\n    add_agent_pos!(offspring, model)\n    return\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The behavior of grass functions differently. If it is fully grown, it is consumable. Otherwise, it cannot be consumed until it regrows after a delay specified by regrowth_time. The grass is tuned from a model stepping function","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function grass_step!(model)\n    @inbounds for p in positions(model) # we don't have to enable bound checking\n        if !(model.fully_grown[p...])\n            if model.countdown[p...] ≤ 0\n                model.fully_grown[p...] = true\n                model.countdown[p...] = model.regrowth_time\n            else\n                model.countdown[p...] -= 1\n            end\n        end\n    end\nend\n\nmodel = initialize_model()","category":"page"},{"location":"examples/predator_prey_fast/#Running-the-model","page":"Predator-prey dynamics","title":"Running the model","text":"","category":"section"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"We will run the model for 500 steps and record the number of sheep, wolves and consumable grass patches after each step. First: initialize the model.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"To view our starting population, we can build an overview plot using abm_plot. We define the plotting details for the wolves and sheep:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"offset(a) = a.type == :sheep ? (-0.7, -0.5) : (-0.3, -0.5)\nashape(a) = a.type == :sheep ? :circle : :utriangle\nacolor(a) = a.type == :sheep ? RGBAf0(1.0, 1.0, 1.0, 0.8) : RGBAf0(0.2, 0.2, 0.2, 0.8)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"and instruct abm_plot how to plot grass as a heatmap:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"grasscolor(model) = model.countdown ./ model.regrowth_time","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"and finally define a colormap for the grass:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"heatkwargs = (colormap = [:brown, :green], colorrange = (0, 1))\n\nplotkwargs = (\n    ac = acolor,\n    as = 15,\n    am = ashape,\n    offset = offset,\n    heatarray = grasscolor,\n    heatkwargs = heatkwargs,\n)\n\nfig, _ = abm_plot(model; plotkwargs...)\nfig","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Now, lets run the simulation and collect some data. Define datacollection:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"sheep(a) = a.type == :sheep\nwolves(a) = a.type == :wolf\ncount_grass(model) = count(model.fully_grown)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Run simulation:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"model = initialize_model()\nn = 500\nadata = [(sheep, count), (wolves, count)]\nmdata = [count_grass]\nadf, mdf = run!(model, sheepwolf_step!, grass_step!, n; adata, mdata)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The following plot shows the population dynamics over time. Initially, wolves become extinct because they consume the sheep too quickly. The few remaining sheep reproduce and gradually reach an equilibrium that can be supported by the amount of available grass.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function plot_population_timeseries(adf, mdf)\n    figure = Figure(resolution = (600, 400))\n    ax = figure[1, 1] = Axis(figure; xlabel = \"Step\", ylabel = \"Population\")\n    sheepl = lines!(ax, adf.step, adf.count_sheep, color = :blue)\n    wolfl = lines!(ax, adf.step, adf.count_wolves, color = :orange)\n    grassl = lines!(ax, mdf.step, mdf.count_grass, color = :green)\n    figure[1, 2] = Legend(figure, [sheepl, wolfl, grassl], [\"Sheep\", \"Wolves\", \"Grass\"])\n    figure\nend\n\nplot_population_timeseries(adf, mdf)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Altering the input conditions, we now see a landscape where sheep, wolves and grass find an equilibrium","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"model = initialize_model(\n    n_wolves = 20,\n    dims = (25, 25),\n    Δenergy_sheep = 5,\n    sheep_reproduce = 0.2,\n    wolf_reproduce = 0.08,\n    seed = 7758,\n)\nadf, mdf = run!(model, sheepwolf_step!, grass_step!, n; adata, mdata)\n\nplot_population_timeseries(adf, mdf)","category":"page"},{"location":"examples/predator_prey_fast/#Video","page":"Predator-prey dynamics","title":"Video","text":"","category":"section"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Given that we have defined plotting functions, making a video is as simple as","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"model = initialize_model(\n    n_wolves = 20,\n    dims = (25, 25),\n    Δenergy_sheep = 5,\n    sheep_reproduce = 0.2,\n    wolf_reproduce = 0.08,\n    seed = 7758,\n)\nabm_video(\n    \"sheepwolf.mp4\",\n    model,\n    sheepwolf_step!,\n    grass_step!;\n    frames = 150,\n    framerate = 8,\n    plotkwargs...,\n)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sheepwolf.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/game_of_life_2D_CA.jl\"","category":"page"},{"location":"examples/game_of_life_2D_CA/#Conway's-game-of-life","page":"Conway's game of life","title":"Conway's game of life","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../game of life.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Game of life on wikipedia.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"It is also available from the Models module as Models.game_of_life.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"using Agents, Random","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Define-the-rules","page":"Conway's game of life","title":"1. Define the rules","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Conway's game of life is a cellular automaton, where each cell of the discrete space contains one agent only.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"The rules of Conway's game of life are defined based on four numbers: Death, Survival, Reproduction, Overpopulation, grouped as (D, S, R, O) Cells die if the number of their living neighbors is <D or >O, survive if the number of their living neighbors is ≤S, come to life if their living neighbors are  ≥R and ≤O.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"rules = (2, 3, 3, 3) # (D, S, R, O)\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Build-the-model","page":"Conway's game of life","title":"2. Build the model","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"First, define an agent type. It needs to have the compulsary id and pos fields, as well as a status field that is true for cells that are alive and false otherwise.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"mutable struct Cell <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    status::Bool\nend","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"The following function builds a 2D cellular automaton given some rules. dims is a tuple of integers determining the width and height of the grid environment. metric specifies how to measure distances in the space, and in our example it actually decides whether cells connect to their diagonal neighbors.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"This function creates a model where all cells are dead.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"function build_model(; rules::Tuple, dims = (100, 100), metric = :chebyshev, seed = 120)\n    space = GridSpace(dims; metric)\n    properties = Dict(:rules => rules)\n    model = ABM(Cell, space; properties, rng = MersenneTwister(seed))\n    idx = 1\n    for x in 1:dims[1]\n        for y in 1:dims[2]\n            add_agent_pos!(Cell(idx, (x, y), false), model)\n            idx += 1\n        end\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Now we define a stepping function for the model to apply the rules to agents. We will also perform a synchronous agent update (meaning that the value of all agents changes after we have decided the new value for each agent individually).","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"function ca_step!(model)\n    new_status = fill(false, nagents(model))\n    for agent in allagents(model)\n        n = alive_neighbors(agent, model)\n        if agent.status == true && (n ≤ model.rules[4] && n ≥ model.rules[1])\n            new_status[agent.id] = true\n        elseif agent.status == false && (n ≥ model.rules[3] && n ≤ model.rules[4])\n            new_status[agent.id] = true\n        end\n    end\n\n    for id in allids(model)\n        model[id].status = new_status[id]\n    end\nend\n\nfunction alive_neighbors(agent, model) # count alive neighboring cells\n    c = 0\n    for n in nearby_agents(agent, model)\n        if n.status == true\n            c += 1\n        end\n    end\n    return c\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"now we can instantiate the model:","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"model = build_model(rules = rules, dims = (50, 50))","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Let's make some random cells on","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"for i in 1:nagents(model)\n    if rand(model.rng) < 0.2\n        model.agents[i].status = true\n    end\nend","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Animate-the-model","page":"Conway's game of life","title":"3. Animate the model","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"We use the InteractiveDynamics.abm_video for creating an animation and saving it to an mp4","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"using InteractiveDynamics\nimport CairoMakie\nCairoMakie.activate!() # hide\n\nac(x) = x.status == true ? :black : :white\nam(x) = x.status == true ? '■' : '□'\nabm_video(\n    \"game of life.mp4\",\n    model,\n    dummystep,\n    ca_step!;\n    title = \"Game of Life\",\n    ac = :black,\n    as = 12,\n    am,\n    framerate = 5,\n    scatterkwargs = (strokewidth = 0,),\n)\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../game of life.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/wright-fisher.jl\"","category":"page"},{"location":"examples/wright-fisher/#Wright-Fisher-model-of-evolution","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"This is one of the simplest models of population genetics that demonstrates the use of sample!. We implement a simple case of the model where we study haploids (cells with a single set of chromosomes) while for simplicity, focus only on one locus (a specific gene). In this example we will be dealing with a population of constant size.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"It is also available from the Models module as Models.wright_fisher.","category":"page"},{"location":"examples/wright-fisher/#A-neutral-model","page":"Wright-Fisher model of evolution","title":"A neutral model","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Imagine a population of n haploid individuals.\nAt each generation, n offsprings replace the parents.\nEach offspring chooses a parent at random and inherits its genetic material.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"using Agents\nnumagents = 100\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Let's define an agent. The genetic value of an agent is a number (trait field).","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"mutable struct Haploid <: AbstractAgent\n    id::Int\n    trait::Float64\nend","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"And make a model without any spatial structure:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"model = ABM(Haploid)","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Create n random individuals:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"for i in 1:numagents\n    add_agent!(model, rand(model.rng))\nend","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"To create a new generation, we can use the sample! function. It chooses random individuals with replacement from the current individuals and updates the model. For example:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"sample!(model, nagents(model))\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"The model can be run for many generations and we can collect the average trait value of the population. To do this we will use a model-step function (see step!) that utilizes sample!:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"modelstep_neutral!(model::ABM) = sample!(model, nagents(model))\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"We can now run the model and collect data. We use dummystep for the agent-step function (as the agents perform no actions).","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"using Statistics: mean\n\ndata, _ = run!(model, dummystep, modelstep_neutral!, 20; adata = [(:trait, mean)])\ndata","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"As expected, the average value of the \"trait\" remains around 0.5.","category":"page"},{"location":"examples/wright-fisher/#A-model-with-selection","page":"Wright-Fisher model of evolution","title":"A model with selection","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"We can sample individuals according to their trait values, supposing that their fitness is correlated with their trait values.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"model = ABM(Haploid)\nfor i in 1:numagents\n    add_agent!(model, rand(model.rng))\nend\n\nmodelstep_selection!(model::ABM) = sample!(model, nagents(model), :trait)\n\ndata, _ = run!(model, dummystep, modelstep_selection!, 20; adata = [(:trait, mean)])\ndata","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Here we see that as time progresses, the trait becomes closer and closer to 1, which is expected - since agents with higher traits have higher probability of being sampled for the next \"generation\".","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/daisyworld.jl\"","category":"page"},{"location":"examples/daisyworld/#Daisyworld","page":"Daisyworld","title":"Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../daisyworld.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Study this example to learn about","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Simple agent properties with complex model interactions\nDiffusion of a quantity in a GridSpace\nIncluding a \"surface property\" in the model\ncounting time in the model and having time-dependent dynamics\nperforming interactive scientific research","category":"page"},{"location":"examples/daisyworld/#Overview-of-Daisyworld","page":"Daisyworld","title":"Overview of Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"This model explores the Gaia hypothesis, which considers the Earth as a single, self-regulating system including both living and non-living parts.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Daisyworld is filled with black and white daisies. Their albedo's differ, with black daisies absorbing light and heat, warming the area around them; white daisies doing the opposite. Daisies can only reproduce within a certain temperature range, meaning too much (or too little) heat coming from the sun and/or surrounds will ultimately halt daisy propagation.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"When the climate is too cold it is necessary for the black daisies to propagate in order to raise the temperature, and vice versa – when the climate is too warm, it is necessary for more white daisies to be produced in order to cool the temperature. The interplay of the living and non living aspects of this world manages to find an equilibrium over a wide range of parameter settings, although with enough external forcing, the daisies will not be able to regulate the temperature of the planet and eventually go extinct.","category":"page"},{"location":"examples/daisyworld/#Defining-the-agent-types","page":"Daisyworld","title":"Defining the agent types","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Daisy has three values (other than the required id and pos for an agent that lives on a GridSpace. Each daisy has an age, confined later by a maximum age set by the user, a breed (either :black or :white) and an associated albedo value, again set by the user. Land represents the surface. We could make Land also have an albedo field, but in this world, the entire surface has the same albedo and thus we make it a model parameter.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that the Land does not necessarily have to be an agent, and one could represent surface temperature via a matrix (parameter of the model). This is done in an older version, see file examples/daisyworld_matrix.jl. The old version has a slight performance advantage. However, the advantage of making the surface composed of agents is that visualization is simple and one can use the interactive application to also visualize surface temperature. It is also available from the Models module as Models.daisyworld.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using Agents\nusing Statistics: mean\nusing Random # hide\n\nmutable struct Daisy <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    breed::Symbol\n    age::Int\n    albedo::Float64 # 0-1 fraction\nend\n\nconst DaisyWorld = ABM{<:GridSpace, Daisy};\nnothing #hide","category":"page"},{"location":"examples/daisyworld/#World-heating","page":"Daisyworld","title":"World heating","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The surface temperature of the world is heated by its sun, but daisies growing upon it absorb or reflect the starlight – altering the local temperature.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function update_surface_temperature!(pos, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    absorbed_luminosity = if isempty(ids) # no daisy\n        # Set luminosity via surface albedo\n        (1 - model.surface_albedo) * model.solar_luminosity\n    else\n        # Set luminosity via daisy albedo\n        (1 - model[ids[1]].albedo) * model.solar_luminosity\n    end\n    # We expect local heating to be 80 ᵒC for an absorbed luminosity of 1,\n    # approximately 30 for 0.5 and approximately -273 for 0.01.\n    local_heating = absorbed_luminosity > 0 ? 72 * log(absorbed_luminosity) + 80 : 80\n    # Surface temperature is the average of the current temperature and local heating.\n    model.temperature[pos...] = (model.temperature[pos...] + local_heating) / 2\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"In addition, temperature diffuses over time","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function diffuse_temperature!(pos, model::DaisyWorld)\n    ratio = get(model.properties, :ratio, 0.5) # diffusion ratio\n    npos = nearby_positions(pos, model)\n    model.temperature[pos...] =\n        (1 - ratio) * model.temperature[pos...] +\n        # Each neighbor is giving up 1/8 of the diffused\n        # amount to each of *its* neighbors\n        sum(model.temperature[p...] for p in npos) * 0.125 * ratio\nend","category":"page"},{"location":"examples/daisyworld/#Daisy-dynamics","page":"Daisyworld","title":"Daisy dynamics","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The final piece of the puzzle is the life-cycle of each daisy. This method defines an optimal temperature for growth. If the temperature gets too hot or too cold, daisies will not wish to propagate. So long as the temperature is favorable, daisies compete for land and attempt to spawn a new plant of their breed in locations close to them.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function propagate!(pos, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    if !isempty(ids)\n        daisy = model[ids[1]]\n        temperature = model.temperature[pos...]\n        # Set optimum growth rate to 22.5 ᵒC, with bounds of [5, 40]\n        seed_threshold = (0.1457 * temperature - 0.0032 * temperature^2) - 0.6443\n        if rand(model.rng) < seed_threshold\n            # Collect all adjacent position that have no daisies\n            empty_neighbors = Tuple{Int,Int}[]\n            neighbors = nearby_positions(pos, model)\n            for n in neighbors\n                if isempty(ids_in_position(n, model))\n                    push!(empty_neighbors, n)\n                end\n            end\n            if !isempty(empty_neighbors)\n                # Seed a new daisy in one of those position\n                seeding_place = rand(model.rng, empty_neighbors)\n                add_agent!(seeding_place, model, daisy.breed, 0, daisy.albedo)\n            end\n        end\n    end\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And if the daisies cross an age threshold, they die out. Death is controlled by the agent_step function","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function agent_step!(agent::Daisy, model::DaisyWorld)\n    agent.age += 1\n    agent.age >= model.max_age && kill_agent!(agent, model)\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The model step function advances Daisyworld's dynamics:","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function model_step!(model)\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n        diffuse_temperature!(p, model)\n        propagate!(p, model)\n    end\n    model.tick += 1\n    solar_activity!(model)\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that solar_activity! changes the incoming solar radiation over time, if the given \"scenario\" (a model parameter) is :ramp. The parameter tick of the model keeps track of time.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function solar_activity!(model::DaisyWorld)\n    if model.scenario == :ramp\n        if model.tick > 200 && model.tick <= 400\n            model.solar_luminosity += model.solar_change\n        end\n        if model.tick > 500 && model.tick <= 750\n            model.solar_luminosity -= model.solar_change / 2\n        end\n    elseif model.scenario == :change\n        model.solar_luminosity += model.solar_change\n    end\nend","category":"page"},{"location":"examples/daisyworld/#Initialising-Daisyworld","page":"Daisyworld","title":"Initialising Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Here, we construct a function to initialize a Daisyworld. We use fill_space! to fill the space with Land instances. Then, we need to know how many daisies of each type to seed the planet with and what their albedo's are. We also want a value for surface albedo, as well as solar intensity (and we also choose between constant or time-dependent intensity with scenario).","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"import StatsBase\nimport DrWatson: @dict\nusing Random\n\nfunction daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2, # % cover of the world surface of white breed\n    init_black = 0.2, # % cover of the world surface of black breed\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    surface_albedo = 0.4,\n    solar_change = 0.005,\n    solar_luminosity = 1.0, # initial luminosity\n    scenario = :default,\n    seed = 165,\n)\n\n    rng = MersenneTwister(seed)\n    space = GridSpace(griddims)\n    properties = @dict max_age surface_albedo solar_luminosity solar_change scenario\n    properties[:tick] = 0\n    properties[:temperature] = zeros(griddims)\n\n    model = ABM(Daisy, space; properties, rng)\n\n    # Populate with daisies: each position has only one daisy (black or white)\n    grid = collect(positions(model))\n    num_positions = prod(griddims)\n    white_positions =\n        StatsBase.sample(grid, Int(init_white * num_positions); replace = false)\n    for wp in white_positions\n        wd = Daisy(nextid(model), wp, :white, rand(model.rng, 0:max_age), albedo_white)\n        add_agent_pos!(wd, model)\n    end\n    allowed = setdiff(grid, white_positions)\n    black_positions =\n        StatsBase.sample(allowed, Int(init_black * num_positions); replace = false)\n    for bp in black_positions\n        wd = Daisy(nextid(model), bp, :black, rand(model.rng, 0:max_age), albedo_black)\n        add_agent_pos!(wd, model)\n    end\n\n    # Adjust temperature to initial daisy distribution\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n    end\n\n    return model\nend","category":"page"},{"location":"examples/daisyworld/#Visualizing-and-animating","page":"Daisyworld","title":"Visualizing & animating","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Lets run the model with constant solar isolation and visualize the result","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide\n\nmodel = daisyworld()","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"To visualize we need to define the necessary functions for abm_plot. We will also utilize its ability to plot an underlying heatmap, which will be the model surface temperature, while daisies will be plotted in black and white as per their breed. Notice that we will explicitly provide a colorrange to the heatmap keywords, otherwise the colormap will be continuously and automatically updated to match the underlying temperature values while we are animating the time evolution.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"daisycolor(a::Daisy) = a.breed\n\nplotkwargs = (\n    ac=daisycolor, as = 12, am = '♠',\n    heatarray = :temperature,\n    heatkwargs = (colorrange = (-20, 60),),\n)\nfig, _ = abm_plot(model; plotkwargs...)\nfig","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And after a couple of steps","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Agents.step!(model, agent_step!, model_step!, 5)\nfig, _ = abm_plot(model; heatarray = model.temperature, plotkwargs...)\nfig","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Let's do some animation now","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"model = daisyworld()\nabm_video(\n    \"daisyworld.mp4\",\n    model,\n    agent_step!,\n    model_step!;\n    title = \"Daisy World\",\n    plotkwargs...,\n)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../daisyworld.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Running this animation for longer hints that this world achieves quasi-equilibrium for some input parameters, where one breed does not totally dominate the other. Of course we can check this easily through data collection. Notice that here we have to define a function breed that returns the daisy's breed field. We cannot use just :breed to automatically find it, because in this mixed agent model, the Land doesn't have any breed.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"black(a) = a.breed == :black\nwhite(a) = a.breed == :white\nadata = [(black, count), (white, count)]\n\nmodel = daisyworld(; solar_luminosity = 1.0)\n\nagent_df, model_df = run!(model, agent_step!, model_step!, 1000; adata)\nfigure = Figure(resolution = (600, 400))\nax = figure[1, 1] = Axis(figure, xlabel = \"tick\", ylabel = \"daisy count\")\nblackl = lines!(ax, agent_df[!, :step], agent_df[!, :count_black], color = :red)\nwhitel = lines!(ax, agent_df[!, :step], agent_df[!, :count_white], color = :blue)\nfigure[1, 2] = Legend(figure, [blackl, whitel], [\"black\", \"white\"], textsize = 12)\nfigure","category":"page"},{"location":"examples/daisyworld/#Time-dependent-dynamics","page":"Daisyworld","title":"Time dependent dynamics","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"To use the time-dependent dynamics we simply use the keyword scenario = :ramp during model creation. However, we also want to see how the planet surface temperature changes and would be nice to plot solar luminosity as well. Thus, we define in addition","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"temperature(model) = mean(model.temperature)\nmdata = [temperature, :solar_luminosity]","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And we run (and plot) everything","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"model = daisyworld(solar_luminosity = 1.0, scenario = :ramp)\nagent_df, model_df =\n    run!(model, agent_step!, model_step!, 1000; adata = adata, mdata = mdata)\n\nfigure = CairoMakie.Figure(resolution = (600, 600))\nax1 = figure[1, 1] = Axis(figure, ylabel = \"daisy count\", textsize = 12)\nblackl = lines!(ax1, agent_df[!, :step], agent_df[!, :count_black], color = :red)\nwhitel = lines!(ax1, agent_df[!, :step], agent_df[!, :count_white], color = :blue)\nfigure[1, 2] = Legend(figure, [blackl, whitel], [\"black\", \"white\"], textsize = 12)\n\nax2 = figure[2, 1] = Axis(figure, ylabel = \"temperature\", textsize = 12)\nax3 = figure[3, 1] = Axis(figure, xlabel = \"tick\", ylabel = \"L\", textsize = 12)\nlines!(ax2, model_df[!, :step], model_df[!, :temperature], color = :red)\nlines!(ax3, model_df[!, :step], model_df[!, :solar_luminosity], color = :red)\nfor ax in (ax1, ax2); ax.xticklabelsvisible = false; end\nfigure","category":"page"},{"location":"examples/daisyworld/#Interactive-scientific-research","page":"Daisyworld","title":"Interactive scientific research","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Julia is an interactive language, and thus everything that you do with Agents.jl can be considered interactive. However, we can do even better by using our interactive application. In this example, rather than describing what solar forcing we want to investigate before hand, we use the interactive application, to control by ourselves, in real time, how much solar forcing is delivered to daisyworld.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"So, let's make an InteractiveDynamics.abm_data_exploration.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using InteractiveDynamics, GLMakie, Random","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"model = daisyworld(; solar_luminosity = 1.0, solar_change = 0.0, scenario = :change)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The only significant addition to use the interactive application is that we make a parameter container for surface albedo and for the rate of change of solar luminosity, and add some labels for clarity.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"params = Dict(\n    :surface_albedo => 0:0.01:1,\n    :solar_change => -0.1:0.01:0.1,\n)\nalabels = [\"black\", \"white\"]\nmlabels = [\"T\", \"L\"]","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And we run it","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"fig, adf, mdf = abm_data_exploration(\n    model, agent_step!, model_step!, params;\n    mdata, adata, alabels, mlabels, plotkwargs...\n)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/forest_fire.jl\"","category":"page"},{"location":"examples/forest_fire/#Forest-fire","page":"Forest fire","title":"Forest fire","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../forest.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The forest fire model is defined as a cellular automaton on a grid. A position can be empty or occupied by a tree which is ok, burning or burnt. We implement a slightly different ruleset to that of Drossel and Schwabl (1992), so that our implementation can be compared with other ABM frameworks","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"A burning position turns into a burnt position\nA tree will burn if at least one neighbor is burning","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The forest has an innate density, which is the proportion of trees initialized as green, however all trees that reside on the left side of the grid are burning. The model is also available from the Models module as Models.forest_fire.","category":"page"},{"location":"examples/forest_fire/#Defining-the-core-structures","page":"Forest fire","title":"Defining the core structures","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Cellular automata don't necessarily require an agent-like structure. Here we will demonstrate how a model focused solution is possible.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"using Agents, Random\nusing InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide\n\n@agent Automata GridAgent{2} begin end\nnothing # hide","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The agent type Automata is effectively a dummy agent, for which we will invoke dummystep when stepping the model.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"We then make a setup function that initializes the model.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"function forest_fire(; density = 0.7, griddims = (100, 100))\n    space = GridSpace(griddims; periodic = false, metric = :euclidean)\n    # The `trees` field is coded such that\n    # Empty = 0, Green = 1, Burning = 2, Burnt = 3\n    forest = ABM(Automata, space; properties = (trees = zeros(Int, griddims),))\n    for I in CartesianIndices(forest.trees)\n        if rand(forest.rng) < density\n            # Set the trees at the left edge on fire\n            forest.trees[I] = I[1] == 1 ? 2 : 1\n        end\n    end\n    return forest\nend\n\nforest = forest_fire()","category":"page"},{"location":"examples/forest_fire/#Defining-the-step!","page":"Forest fire","title":"Defining the step!","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"function tree_step!(forest)\n    # Find trees that are burning (coded as 2)\n    for I in findall(isequal(2), forest.trees)\n        for idx in nearby_positions(I.I, forest)\n            # If a neighbor is Green (1), set it on fire (2)\n            if forest.trees[idx...] == 1\n                forest.trees[idx...] = 2\n            end\n        end\n        # Finally, any burning tree is burnt out (2)\n        forest.trees[I] = 3\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/forest_fire/#Running-the-model","page":"Forest fire","title":"Running the model","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Agents.step!(forest, dummystep, tree_step!, 1)\ncount(t == 3 for t in forest.trees) # Number of burnt trees on step 1","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Agents.step!(forest, dummystep, tree_step!, 10)\ncount(t == 3 for t in forest.trees) # Number of burnt trees on step 11","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Now we can do some data collection as well using an aggregate function percentage:","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Random.seed!(2)\nforest = forest_fire(griddims = (20, 20))\nburnt_percentage(f) = count(t == 3 for t in f.trees) / prod(size(f.trees))\nmdata = [burnt_percentage]\n\n_, data = run!(forest, dummystep, tree_step!, 10; mdata)\ndata","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Now let's plot the model. We use green for unburnt trees, red for burning and a dark red for burnt.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"forest = forest_fire()\nAgents.step!(forest, dummystep, tree_step!, 1)\n\nplotkwargs = (\n    add_colorbar = false,\n    heatarray = :trees,\n    heatkwargs = (\n        colorrange = (0, 3),\n        colormap = cgrad([:white, :green, :red, :darkred]; categorical = true),\n    ),\n)\nfig, _ = abm_plot(forest; plotkwargs...)\nfig","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"or animate it","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Random.seed!(10)\nforest = forest_fire(density = 0.6)\nadd_agent!(forest) # Add one dummy agent so that abm_video will allow us to plot.\nabm_video(\n    \"forest.mp4\",\n    forest,\n    dummystep,\n    tree_step!;\n    as = 0,\n    framerate = 5,\n    frames = 20,\n    spf = 5,\n    title = \"Forest Fire\",\n    plotkwargs...,\n)\nnothing # hide","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../forest.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/fractal_growth.jl\"","category":"page"},{"location":"examples/fractal_growth/#Fractal-Growth","page":"Fractal Growth","title":"Fractal Growth","text":"","category":"section"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../fractal.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"This model follows the process known as diffusion-limited aggregation to simulate the growth of fractals. It is a kinetic process that consists of randomly diffusing particles giving rise to fractal-like structures resembling those observed naturally. This examplet is based off of \"Particularly Stuck\" example in Complexity Explorables.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The environment is a two dimensional, continuous space world. Agents are particles that diffuse and aggregate to form fractals. Initially, there are particles of random size distributed across the space, and one static particle in the center that forms the seed for the fractal growth. As moving particles collide with the seed or any particle that previously collided with the seed, it gets stuck and contributes to the fractal. As a particle gets stuck, another one is created at a circular border around the center to feed the growth.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"It is also available from the Models module as Models.fractal_growth.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"using Agents, LinearAlgebra\nusing Random # hide","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"We use the @agent macro to conveniently define a Particle agent. Each agent has a radius, representing the particle size, a boolean to define whether it is stuck and part of the fractal, and an axis around which it spins (elaborated on later). In addition, since we use the ContinuousAgent type, the @agent macro also provides each agent with fields for id, pos (its position in space) and vel (its velocity).","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"@agent Particle ContinuousAgent{2} begin\n    radius::Float64\n    is_stuck::Bool\n    spin_axis::Array{Float64,1}\nend","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"A custom constructor allows convenient creation of agents.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"Particle(\n    id::Int,\n    radius::Float64,\n    spin_clockwise::Bool;\n    pos = (0.0, 0.0),\n    is_stuck = false,\n) = Particle(id, pos, (0.0, 0.0), radius, is_stuck, [0.0, 0.0, spin_clockwise ? -1.0 : 1.0])","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"We also define a few utility functions for ease of implementation. rand_circle returns a random point on the unit circle. particle_radius generates a random radius for a particle, within given range defined by min_radius and max_radius. If max_radius < min_radius, it returns min_radius: allowing a fixed particle size to be specified.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"rand_circle(rng) = (θ = rand(rng, 0.0:0.1:359.9); (cos(θ), sin(θ)))\nparticle_radius(min_radius::Float64, max_radius::Float64, rng) =\n    min_radius <= max_radius ? rand(rng, min_radius:0.01:max_radius) : min_radius","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The initialize_model function returns a new model containing particles placed randomly in the given space and one seed particle at the center.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"function initialize_model(;\n    initial_particles::Int = 100, # initial particles in the model, not including the seed\n    # size of the space in which particles exist\n    space_extents::NTuple{2,Float64} = (150.0, 150.0),\n    speed = 0.5, # speed of particle movement\n    vibration = 0.55, # amplitude of particle vibration\n    attraction = 0.45, # velocity of particles towards the center\n    spin = 0.55, # tangential velocity with which particles orbit the center\n    # fraction of particles orbiting clockwise. The rest are anticlockwise\n    clockwise_fraction = 0.0,\n    min_radius = 1.0, # minimum radius of any particle\n    max_radius = 2.0, # maximum radius of any particle\n)\n    properties = Dict(\n        :speed => speed,\n        :vibration => vibration,\n        :attraction => attraction,\n        :spin => spin,\n        :clockwise_fraction => clockwise_fraction,\n        :min_radius => min_radius,\n        :max_radius => max_radius,\n        :spawn_count => 0,\n    )\n    # space is periodic to allow particles going off one edge to wrap around to the opposite\n    space = ContinuousSpace(space_extents, 1.0; periodic = true)\n    model = ABM(Particle, space; properties)\n    center = space_extents ./ 2.0\n    for i in 1:initial_particles\n        particle = Particle(\n            i,\n            particle_radius(min_radius, max_radius, model.rng),\n            rand(model.rng) < clockwise_fraction,\n        )\n        # `add_agent!` automatically gives the particle a random position in the space\n        add_agent!(particle, model)\n    end\n    # create the seed particle\n    particle = Particle(\n        initial_particles + 1,\n        particle_radius(min_radius, max_radius, model.rng),\n        true;\n        pos = center,\n        is_stuck = true,\n    )\n    # `add_agent_pos!` will use the position of the agent passed in, instead of assigning it\n    # to a random value\n    add_agent_pos!(particle, model)\n    return model\nend","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The agent_step! function simulates particle motion for those who are not yet stuck. For each particle, we first perform a crude distance check to all other particles. If the current particle intersects any particle in the fractal, it also becomes part of the fractal and is not simulated further. Agent velocity has a radial component that attracts it towards the center, a tangential component that makes it orbit around the center, and a random component that simulates vibration of the particle. The velocity is scaled to be inversely proportional to the square of the particle's radius, so that larger particles move slower. The speed parameter is implemented as the time difference between successive steps of the simulation. A larger value causes particles to move more per step, but leads to inaccuracies as particles do not move through the intervening space.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"function agent_step!(agent::Particle, model)\n    agent.is_stuck && return\n\n    for id in nearby_ids(agent.pos, model, agent.radius)\n        if model[id].is_stuck\n            agent.is_stuck = true\n            # increment count to make sure another particle is spawned as this one gets stuck\n            model.spawn_count += 1\n            return\n        end\n    end\n    # radial vector towards the center of the space\n    radial = model.space.extent ./ 2.0 .- agent.pos\n    radial = radial ./ norm(radial)\n    # tangential vector in the direction of orbit of the particle\n    tangent = Tuple(cross([radial..., 0.0], agent.spin_axis)[1:2])\n    agent.vel =\n        (\n            radial .* model.attraction .+ tangent .* model.spin .+\n            rand_circle(model.rng) .* model.vibration\n        ) ./ (agent.radius^2.0)\n    move_agent!(agent, model, model.speed)\nend","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The model_step! function serves the sole purpose of spawning additional particles as they get stuck to the growing fractal.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"function model_step!(model)\n    while model.spawn_count > 0\n        particle = Particle(\n            nextid(model),\n            particle_radius(model.min_radius, model.max_radius, model.rng),\n            rand(model.rng) < model.clockwise_fraction;\n            pos = (rand_circle(model.rng) .+ 1.0) .* model.space.extent .* 0.49,\n        )\n        add_agent_pos!(particle, model)\n        model.spawn_count -= 1\n    end\nend","category":"page"},{"location":"examples/fractal_growth/#Running-the-model","page":"Fractal Growth","title":"Running the model","text":"","category":"section"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"We run the model using the InteractiveDynamics package with GLMakie backend so the fractal growth can be visualised as it happens. InteractiveDynamics provides the abm_video function to easily record a video of the simulation running.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"Random.seed!(42) # hide\nmodel = initialize_model()\n\nusing InteractiveDynamics\nimport CairoMakie\nCairoMakie.activate!() # hide\n\n# Particles that are stuck and part of the fractal are shown in red, for visual distinction\nparticle_color(a::Particle) = a.is_stuck ? :red : :blue\n# The visual size of particles corresponds to their radius, and has been calculated\n# for the default value of `space_extents` of the `initialize_model` function. It will\n# not look accurate on other values.\nparticle_size(a::Particle) = 7.5 * a.radius\n\nabm_video(\n    \"fractal.mp4\",\n    model,\n    agent_step!,\n    model_step!;\n    ac = particle_color,\n    as = particle_size,\n    am = '●',\n    spf = 10,\n    frames = 600,\n    framerate = 25,\n    scatterkwargs = (strokewidth = 0.5, strokecolor = :white),\n)\nnothing # hide","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../fractal.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"Using InteractiveDynamics simulation parameters can also be tweaked dynamically. This makes use of the InteractiveDynamics.abm_data_exploration function.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"using InteractiveDynamics\nusing GLMakie\nmodel = initialize_model()","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"params defines the range in which different parameter values can be adjusted through sliders.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"params = (\n    :attraction => 0.0:0.01:2.0,\n    :speed => 0.0:0.01:2.0,\n    :vibration => 0.0:0.01:2.0,\n    :spin => 0.0:0.01:2.0,\n    :clockwise_fraction => 0.0:0.01:1.0,\n    :min_radius => 0.5:0.01:3.0,\n    :max_radius => 0.5:0.01:3.0,\n)\n\nparticle_size(a::Particle) = 4 * a.radius\nabm_data_exploration(\n    model,\n    agent_step!,\n    model_step!,\n    params;\n    ac = particle_color,\n    as = particle_size,\n    am = '⚪',\n)","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/fractal_interact.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/social_distancing.jl\"","category":"page"},{"location":"examples/social_distancing/#Continuous-space-social-distancing","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist5.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"This is a model similar to our SIR model for the spread of COVID-19. But instead of having different cities, we let agents move in one continuous space and transfer the disease if they come into contact with one another. This model is partly inspired by this article, and can complement the SIR graph model. The graph model can model virus transfer between cities, whilst this model can be used to study what happens within a city.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"The example here serves additionally as an introduction to using continuous space, modelling billiard-like collisions in that space, and animating the agent motion in the space. Notice that a detailed description of the basics of the model regarding disease spreading exists in the SIR example, and is not repeated here.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"It is also available from the Models module as Models.social_distancing.","category":"page"},{"location":"examples/social_distancing/#Moving-agents-in-continuous-space","page":"Continuous space social distancing","title":"Moving agents in continuous space","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Let us first create a simple model where balls move around in a continuous space. We need to create agents that comply with ContinuousSpace, i.e. they have a pos and vel fields, both of which are tuples of float numbers.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"using Agents, Random\n\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    mass::Float64\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"The mass field will come in handy later on, when we implement social isolation (i.e. that some agents don't move and can't be moved).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Let's also initialize a trivial model with continuous space","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"function ball_model(; speed = 0.002)\n    space2d = ContinuousSpace((1, 1), 0.02)\n    model = ABM(Agent, space2d, properties = Dict(:dt => 1.0), rng = MersenneTwister(42))\n\n    # And add some agents to the model\n    for ind in 1:500\n        pos = Tuple(rand(model.rng, 2))\n        vel = sincos(2π * rand(model.rng)) .* speed\n        add_agent!(pos, model, vel, 1.0)\n    end\n    return model\nend\n\nmodel = ball_model()","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We took advantage of the functionality of add_agent! that creates the agents automatically. For now all agents have the same absolute speed, and mass.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"The agent step function for now is trivial. It is just move_agent! in continuous space","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"agent_step!(agent, model) = move_agent!(agent, model, model.dt)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"dt is our time resolution, but we will talk about this more later! Cool, let's see now how this model evolves.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide\n\nabm_video(\n    \"socialdist1.mp4\",\n    model,\n    agent_step!;\n    title = \"Ball Model\",\n    frames = 50,\n    spf = 2,\n    framerate = 25,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist1.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"As you can see the agents move in a straight line in periodic space. There is no interaction yet. Let's change that.","category":"page"},{"location":"examples/social_distancing/#Billiard-like-interaction","page":"Continuous space social distancing","title":"Billiard-like interaction","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We will model the agents as balls that collide with each other. To this end, we will use two functions from the continuous space API:","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"interacting_pairs\nelastic_collision!","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We want all agents to interact in one go, and we want to avoid double interactions (as instructed by interacting_pairs), so we define a model step and re-run the animation.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"function model_step!(model)\n    for (a1, a2) in interacting_pairs(model, 0.012, :nearest)\n        elastic_collision!(a1, a2, :mass)\n    end\nend\n\nmodel2 = ball_model()\n\nabm_video(\n    \"socialdist2.mp4\",\n    model2,\n    agent_step!,\n    model_step!;\n    title = \"Billiard-like\",\n    frames = 50,\n    spf = 2,\n    framerate = 25,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist2.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Alright, this works great so far!","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"warning: Agents.jl is not a billiards simulator!\nPlease understand that Agents.jl does not accurately simulate billiard systems. This is the job of Julia packages HardSphereDynamics.jl or DynamicalBilliards.jl. In Agents.jl we only provide an approximating function elastic_collision!. The accuracy of this simulation increases as the time resolution dt decreases, but even in the limit dt → 0 we still don't reach the accuracy of proper billiard packages.Also notice that the plotted size of the circles representing agents is not deduced from the interaction_radius (as it should). We only eye-balled it to look similar enough.","category":"page"},{"location":"examples/social_distancing/#Immovable-agents","page":"Continuous space social distancing","title":"Immovable agents","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"For the following social distancing example, it will become crucial that some agents don't move, and can't be moved (i.e. they stay \"isolated\"). This is very easy to do with the elastic_collision! function, we only have to make some agents have infinite mass","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"model3 = ball_model()\n\nfor id in 1:400\n    agent = model3[id]\n    agent.mass = Inf\n    agent.vel = (0.0, 0.0)\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"let's animate this again","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"abm_video(\n    \"socialdist3.mp4\",\n    model3,\n    agent_step!,\n    model_step!;\n    title = \"Billiard-like with stationary agents\",\n    frames = 50,\n    spf = 2,\n    framerate = 25,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist3.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/#Adding-Virus-spread-(SIR)","page":"Continuous space social distancing","title":"Adding Virus spread (SIR)","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We now add more functionality to these agents, according to the SIR model (see previous example). They can be infected with a disease and transfer the disease to other agents around them.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"mutable struct PoorSoul <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    mass::Float64\n    days_infected::Int  # number of days since is infected\n    status::Symbol  # :S, :I or :R\n    β::Float64\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Here β is the transmission probability, which we choose to make an agent parameter instead of a model parameter. It reflects the level of hygiene of an individual. In a realistic scenario, the actual virus transmission would depend on the β value of both agents, but we don't do that here for simplicity.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We also significantly modify the model creation, to have SIR-related parameters. Each step in the model corresponds to one hour.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"const steps_per_day = 24\n\nusing DrWatson: @dict\nfunction sir_initiation(;\n    infection_period = 30 * steps_per_day,\n    detection_time = 14 * steps_per_day,\n    reinfection_probability = 0.05,\n    isolated = 0.0, # in percentage\n    interaction_radius = 0.012,\n    dt = 1.0,\n    speed = 0.002,\n    death_rate = 0.044, # from website of WHO\n    N = 1000,\n    initial_infected = 5,\n    seed = 42,\n    βmin = 0.4,\n    βmax = 0.8,\n)\n\n    properties = @dict(\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        death_rate,\n        interaction_radius,\n        dt,\n    )\n    space = ContinuousSpace((1,1), 0.02)\n    model = ABM(PoorSoul, space, properties = properties, rng = MersenneTwister(seed))\n\n    # Add initial individuals\n    for ind in 1:N\n        pos = Tuple(rand(model.rng, 2))\n        status = ind ≤ N - initial_infected ? :S : :I\n        isisolated = ind ≤ isolated * N\n        mass = isisolated ? Inf : 1.0\n        vel = isisolated ? (0.0, 0.0) : sincos(2π * rand(model.rng)) .* speed\n\n        # very high transmission probability\n        # we are modelling close encounters after all\n        β = (βmax - βmin) * rand(model.rng) + βmin\n        add_agent!(pos, model, vel, mass, 0, status, β)\n    end\n\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Notice the constant steps_per_day, which approximates how many model steps correspond to one day (since the parameters we used in the previous graph SIR example were given in days).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"To visualize this model, we will use black color for the susceptible, red for the infected infected and green for the recovered, leveraging InteractiveDynamics.abm_plot.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"sir_model = sir_initiation()\n\nsir_colors(a) = a.status == :S ? \"#2b2b33\" : a.status == :I ? \"#bf2642\" : \"#338c54\"\n\nfig, abmstepper = abm_plot(sir_model; ac = sir_colors)\nfig # display figure","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We have increased the size of the model 10-fold (for more realistic further analysis)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"To actually spread the virus, we modify the model_step! function, so that individuals have a probability to transmit the disease as they interact.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"function transmit!(a1, a2, rp)\n    # for transmission, only 1 can have the disease (otherwise nothing happens)\n    count(a.status == :I for a in (a1, a2)) ≠ 1 && return\n    infected, healthy = a1.status == :I ? (a1, a2) : (a2, a1)\n\n    rand(model.rng) > infected.β && return\n\n    if healthy.status == :R\n        rand(model.rng) > rp && return\n    end\n    healthy.status = :I\nend\n\nfunction sir_model_step!(model)\n    r = model.interaction_radius\n    for (a1, a2) in interacting_pairs(model, r, :nearest)\n        transmit!(a1, a2, model.reinfection_probability)\n        elastic_collision!(a1, a2, :mass)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Notice that it is not necessary that the transmission interaction radius is the same as the billiard-ball dynamics. We only have them the same here for convenience, but in a real model they will probably differ.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We also modify the agent_step! function, so that we keep track of how long the agent has been infected, and whether they have to die or not.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"function sir_agent_step!(agent, model)\n    move_agent!(agent, model, model.dt)\n    update!(agent)\n    recover_or_die!(agent, model)\nend\n\nupdate!(agent) = agent.status == :I && (agent.days_infected += 1)\n\nfunction recover_or_die!(agent, model)\n    if agent.days_infected ≥ model.infection_period\n        if rand(model.rng) ≤ model.death_rate\n            kill_agent!(agent, model)\n        else\n            agent.status = :R\n            agent.days_infected = 0\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Alright, now we can animate this process for default parameters","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"sir_model = sir_initiation()\n\nabm_video(\n    \"socialdist4.mp4\",\n    sir_model,\n    sir_agent_step!,\n    sir_model_step!;\n    title = \"SIR model\",\n    frames = 100,\n    ac = sir_colors,\n    as = 10,\n    spf = 1,\n    framerate = 20,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist4.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/#Exponential-spread","page":"Continuous space social distancing","title":"Exponential spread","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"We can all agree that these animations look interesting, but let's do some actual analysis of this model. The quantity we wish to look at is the number of infected over time, so let's calculate this, similarly with the graph SIR model.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"infected(x) = count(i == :I for i in x)\nrecovered(x) = count(i == :R for i in x)\nadata = [(:status, infected), (:status, recovered)]\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Let's do the following runs, with different parameters probabilities","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"r1, r2 = 0.04, 0.33\nβ1, β2 = 0.5, 0.1\nsir_model1 = sir_initiation(reinfection_probability = r1, βmin = β1)\nsir_model2 = sir_initiation(reinfection_probability = r2, βmin = β1)\nsir_model3 = sir_initiation(reinfection_probability = r1, βmin = β2)\n\ndata1, _ = run!(sir_model1, sir_agent_step!, sir_model_step!, 2000; adata)\ndata2, _ = run!(sir_model2, sir_agent_step!, sir_model_step!, 2000; adata)\ndata3, _ = run!(sir_model3, sir_agent_step!, sir_model_step!, 2000; adata)\n\ndata1[(end-10):end, :]","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Now, we can plot the number of infected versus time","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"using CairoMakie\nCairoMakie.activate!() # hide\nfigure = Figure()\nax = figure[1, 1] = Axis(figure; ylabel = \"Infected\")\nl1 = lines!(ax, data1[:, dataname((:status, infected))], color = :orange)\nl2 = lines!(ax, data2[:, dataname((:status, infected))], color = :blue)\nl3 = lines!(ax, data3[:, dataname((:status, infected))], color = :green)\nfigure[1, 2] =\n    Legend(figure, [l1, l2, l3], [\"r=$r1, beta=$β1\", \"r=$r2, beta=$β1\", \"r=$r1, beta=$β2\"])\nfigure","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Exponential growth is evident in all cases.","category":"page"},{"location":"examples/social_distancing/#Social-distancing","page":"Continuous space social distancing","title":"Social distancing","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Of course in reality a dampening mechanism will (hopefully) happen before all of the population is infected: a vaccine. This effectively introduces a 4th type of status, :V for vaccinated. This type can't get infected, and thus all remaining individuals that are already infected will (hopefully) survive or die out.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Until that point, social distancing is practiced. The best way to model social distancing is to make some agents simply not move (which feels like it approximates reality better).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"sir_model = sir_initiation(isolated = 0.8)\nabm_video(\n    \"socialdist5.mp4\",\n    sir_model,\n    sir_agent_step!,\n    sir_model_step!;\n    title = \"Social Distancing\",\n    frames = 100,\n    spf = 2,\n    ac = sir_colors,\n    framerate = 20,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist5.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Here we let some 20% of the population not be isolated, probably teenagers still partying, or anti-vaxers / flat-earthers that don't believe in science. Still, you can see that the spread of the virus is dramatically contained.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Let's look at the actual numbers, because animations are cool, but science is even cooler.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"r4 = 0.04\nsir_model4 = sir_initiation(reinfection_probability = r4, βmin = β1, isolated = 0.8)\n\ndata4, _ = run!(sir_model4, sir_agent_step!, sir_model_step!, 2000; adata)\n\nl4 = lines!(ax, data4[:, dataname((:status, infected))], color = :red)\nfigure[1, 2] = Legend(\n    figure,\n    [l1, l2, l3, l4],\n    [\"r=$r1, beta=$β1\", \"r=$r2, beta=$β1\", \"r=$r1, beta=$β2\", \"r=$r4, social distancing\"],\n)\nfigure","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing","title":"Continuous space social distancing","text":"Here you can see the characteristic \"flattening the curve\" phrase you hear all over the news.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/maze.jl\"","category":"page"},{"location":"examples/maze/#Maze-Solver","page":"Maze Solver","title":"Maze Solver","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../maze.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"Consider a scenario where a walker agent is stuck in a maze. Finding the shortest path through an arbitrary maze or map is simulated using a Pathfinding.AStar and its walkmap map property.","category":"page"},{"location":"examples/maze/#Setup","page":"Maze Solver","title":"Setup","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"using Agents, Agents.Pathfinding\nusing FileIO # To load images you also need ImageMagick available to your project","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"The Walker agent needs no special property, just the id and position from @agent.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"@agent Walker GridAgent{2} begin end","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"The maze is stored as a simple .bmp image, where each pixel corresponds to a position on the grid. White pixels correspond to walkable regions of the maze.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"function initalize_model(map_url)\n    # Load the maze from the image file. White values can be identified by a\n    # non-zero red component\n    maze = BitArray(map(x -> x.r > 0, load(download(map_url))))\n    # The size of the space is the size of the maze\n    space = GridSpace(size(maze); periodic = false)\n    # Create a pathfinder using the AStar algorithm by providing the space and specifying\n    # the `walkmap` parameter for the pathfinder.\n    # Since we are interested in the most direct path to the end, the default\n    # `DirectDistance` is appropriate.\n    # `diagonal_movement` is set to false to prevent cutting corners by going along\n    # diagonals.\n    pathfinder = AStar(space; walkmap=maze, diagonal_movement=false)\n    model = ABM(Walker, space)\n    # Place a walker at the start of the maze\n    walker = Walker(1, (1, 4))\n    add_agent_pos!(walker, model)\n    # The walker's movement target is the end of the maze.\n    set_target!(walker, (41, 32), pathfinder)\n\n    return model, pathfinder\nend\n\n# Our sample walkmap\nmap_url =\n    \"https://raw.githubusercontent.com/JuliaDynamics/\" *\n    \"JuliaDynamics/master/videos/agents/maze.bmp\"\nmodel, pathfinder = initalize_model(map_url)","category":"page"},{"location":"examples/maze/#Dynamics","page":"Maze Solver","title":"Dynamics","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"Stepping the agent is a trivial matter of calling move_along_route! to move it along it's path to the target.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"agent_step!(agent, model) = move_along_route!(agent, model, pathfinder)","category":"page"},{"location":"examples/maze/#Visualization","page":"Maze Solver","title":"Visualization","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"Visualizing the Walker move through the maze is handled through InteractiveDynamics.abm_plot.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"The heatarray keyword argument allows plotting the maze as a heatmap behind the agent.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"abm_video(\n    \"maze.mp4\",\n    model,\n    agent_step!;\n    resolution=(700,700),\n    frames=310,\n    framerate=30,\n    ac=:red,\n    as=11,\n    heatarray = _ -> pathfinder.walkmap,\n    add_colorbar = false,\n)\nnothing # hide","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../maze.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/opinion_spread.jl\"","category":"page"},{"location":"examples/opinion_spread/#Opinion-spread","page":"Opinion spread","title":"Opinion spread","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../opinion.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"This is a simple model of how an opinion spreads through a community. Each individual has a number of opinions as a list of integers. They can change their opinion by changing the numbers in the list.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Agents can change their opinion at each step. They choose one of their neighbors randomly, and adopt one of the neighbor's opinions. They are more likely to adopt their neighbor's opinion if they share more opinions with each other.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"using Agents\nusing InteractiveDynamics # plotting agents\nusing CairoMakie # for static plotting\nCairoMakie.activate!() # hide\nusing Random # hide\nusing StatsBase","category":"page"},{"location":"examples/opinion_spread/#Building-the-model","page":"Opinion spread","title":"Building the model","text":"","category":"section"},{"location":"examples/opinion_spread/#.-Model-creation","page":"Opinion spread","title":"1. Model creation","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"mutable struct Citizen <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    stabilized::Bool\n    opinion::Array{Int,1}\n    prev_opinion::Array{Int,1}\nend\n\nfunction create_model(; dims = (10, 10), nopinions = 3, levels_per_opinion = 4)\n    space = GridSpace(dims)\n    properties = Dict(:nopinions => nopinions)\n    model = AgentBasedModel(\n        Citizen,\n        space,\n        scheduler = Schedulers.randomly,\n        properties = properties,\n    )\n    for pos in positions(model)\n        add_agent!(\n            pos,\n            model,\n            false,\n            sample(model.rng, 1:levels_per_opinion, nopinions, replace = false),\n            sample(model.rng, 1:levels_per_opinion, nopinions, replace = false)\n        )\n    end\n    return model\nend","category":"page"},{"location":"examples/opinion_spread/#.-Stepping-functions","page":"Opinion spread","title":"2. Stepping functions","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"function adopt!(agent, model)\n    neighbor = sample(model.rng, collect(nearby_ids(agent, model))) # Randomly select a neighbor.\n    neighbor_opinions = model[neighbor].opinion # Look up neighbor's opinions.\n    agent_opinions = agent.opinion # Look up agent's opinions.\n    nmatches = length(intersect(neighbor_opinions, agent_opinions)) # Count how many opinions the neighbor and agent have in common.\n\n    if nmatches < model.nopinions && rand(model.rng) < nmatches / model.nopinions\n        neighbor_opinion = sample(model.rng, setdiff(neighbor_opinions, agent_opinions)) # Find which opinions the neighbor has that the agent doesn't and randomly pick one for the agent to adopt.\n        agent_opinion = sample(model.rng, setdiff(agent_opinions, neighbor_opinions)) # Find which opinions the agent has that the neighbour doesn't and randomly pick one to change.\n        replace!(agent.opinion, agent_opinion => neighbor_opinion) # Replace agent's opinion with neighbor's opinion.\n    end\nend\n\nfunction update_prev_opinion!(agent, model)\n    for i in 1:(model.nopinions)\n        agent.prev_opinion[i] = agent.opinion[i]\n    end\nend\n\nfunction is_stabilized!(agent, model)\n    if agent.prev_opinion == agent.opinion\n        agent.stabilized = true\n    else\n        agent.stabilized = false\n    end\nend\n\nfunction agent_step!(agent, model)\n    update_prev_opinion!(agent, model)\n    adopt!(agent, model)\n    is_stabilized!(agent, model)\nend","category":"page"},{"location":"examples/opinion_spread/#Running-the-model","page":"Opinion spread","title":"Running the model","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"First, we create a stopping condition, which runs the model until all agents stabilize.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"rununtil(model, s) = count(a -> a.stabilized, allagents(model)) == length(positions(model))","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Then we create our model, run it and collect some information","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"model = create_model(nopinions = 3, levels_per_opinion = 4)\n\nagentdata, _ = run!(model, agent_step!, dummystep, rununtil, adata = [(:stabilized, count)])","category":"page"},{"location":"examples/opinion_spread/#Plotting","page":"Opinion spread","title":"Plotting","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"The plot shows the number of stable agents, that is, number of agents whose opinions don't change from one step to the next. Note that the number of stable agents can fluctuate before the final convergence.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"f = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Generation\",\n        ylabel = \"# of stabilized agents\",\n        title = \"Population Stability\",\n    )\nlines!(ax, 1:size(agentdata, 1), agentdata.count_stabilized, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/opinion_spread/#Animation","page":"Opinion spread","title":"Animation","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Here is an animation that shows the stabilization of agent opinions over time.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Random.seed!(648) # hide\nac(agent) = agent.stabilized == true ? :purple : :yellow\nmodel = create_model(nopinions = 3, levels_per_opinion = 4)\n\nabm_video(\n    \"opinion.mp4\",\n    model,\n    agent_step!;\n    ac = ac,\n    am = '■',\n    as = 20,\n    framerate = 20,\n    frames = 150,\n    title = \"Opinion Spread\",\n)\nnothing # hide","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../opinion.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/battle.jl\"","category":"page"},{"location":"examples/battle/#Battle-Royale","page":"Battle Royale","title":"Battle Royale","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../battle.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"This example illustrates how to leverage higher dimensions of a GridSpace to identify the distance from neighbors not just spatially, but also categorically. We'll also use the walk! function extensively.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The Models module includes this example as Models.battle.","category":"page"},{"location":"examples/battle/#Rules-of-Engagement","page":"Battle Royale","title":"Rules of Engagement","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Agents wander around the map looking for opponents. When a grid space is occupied by two or more agents there will be a battle. With experience gained from the fight, the victor searches for more opponents to crush and losers scurry away defeated or possibly even die. This process repeats until there is a single, definitive winner.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"For this battle ground to exist, the following rules must be followed:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Agents have an experience level, starting at level 1 up to a maximum of 10.\nAgents will search for the nearest worthy opponent (one with equal or ±1 experience level) and move towards them to attack, so long as something more important doesn't happen, which could be\nA tougher opponent (with experience level +2 or higher) is nearby: run!\nThere are no worthy opponents available, but there are weak ones (with experience level -2 or lower): chase them down.\nCapture and taunt a weaker opponent, then kill them.\nNotice a tough opponent is occupied, sneak up and kill them.\nThere is no-one worthy to fight, but also no-one left to taunt. All bets are off: THERE CAN BE ONLY ONE.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Battles are won by weighted chance - a higher level gives an agent a larger chance of winning, but does not guarantee it. When a victor is chosen","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The difference in experience between opponents is swapped.\nIf an agents experience reaches 0, they die.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Captured opponents will be killed once taunted. The captor will gain half of their experience. If an opportunist manages to take the captor by surprise, they can gain up to half of the captor's experience. This means a level 1 agent may eliminate a level 10 captor and jump straight to level 6.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Once all rules of engagement have been exhausted, the final showdown begins. Opponents fight their closest adversary regardless of experience level. Winner takes all.","category":"page"},{"location":"examples/battle/#Model-Setup","page":"Battle Royale","title":"Model Setup","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"using Random # hide\nusing Agents\nusing InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!() # hide\n\nmutable struct Fighter <: AbstractAgent\n    id::Int\n    pos::Dims{3}\n    has_prisoner::Bool\n    capture_time::Int\n    shape::Symbol # For plotting\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"As you can see, the properties of out agent are very simple and contain only two parameters that are needed to store context from one time step to the next. All other properties needed are stored in the space. pos is three-dimensional, two for the actual space agents move within, and a third categorical dimension representing their level. shape is used solely for plotting (well, used once just for convenience).","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Now let's set up the battle field:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function battle(; fighters = 50)\n    model = ABM(\n        Fighter,\n        GridSpace((100, 100, 10); periodic = false);\n        scheduler = Schedulers.randomly,\n    )\n\n    n = 0\n    while n != fighters\n        pos = (rand(model.rng, 1:100, 2)..., 1) # Start at level 1\n        if isempty(pos, model)\n            add_agent!(pos, model, false, 0, :diamond)\n            n += 1\n        end\n    end\n\n    return model\nend\n\nRandom.seed!(6547) # hide\nmodel = battle()","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"50 opponents positioned randomly on a 100x100 grid, with no escape (periodic = false). To leverage categorical dimensions fully, non-periodic chebyshev space is necessary.","category":"page"},{"location":"examples/battle/#Game-Dynamics","page":"Battle Royale","title":"Game Dynamics","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"To implement the rules of engagement, only an agent_step! function is required, along with a few helper functions.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"space(agent) = agent.pos[1:2]\nlevel(agent) = agent.pos[3]","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"space allows us to invoke a number of helpful utilities provided by Agents.jl but only operate on our spatial dimensions, level is a wrapper to access the agent's experience easily.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Nearest agents that satisfy our search criteria can be identified via Euclidean distance solely on the spatial dimensions of our GridSpace.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function closest_target(agent::Fighter, ids::Vector{Int}, model::ABM)\n    if length(ids) == 1\n        closest = ids[1]\n    else\n        close_id = argmin(map(id -> edistance(space(agent), space(model[id]), model), ids))\n        closest = ids[close_id]\n    end\n    return model[closest]\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Since our battles are only between opponents with equal, or as much as one level apart, the odds can be set explicitly. Stronger opponents have twice the capacity of winning a match.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function battle!(one::Fighter, two::Fighter, model)\n    if level(one) == level(two)\n        # Odds are equivalent\n        one_winner = rand(model.rng) < 0.5\n    elseif level(one) > level(two)\n        # Odds are in favor of one\n        one_winner = 2 * rand(model.rng) > rand(model.rng)\n    else\n        # Odds are in favor of two\n        one_winner = rand(model.rng) > 2 * rand(model.rng)\n    end\n\n    one_winner ? (up = one; down = two) : (up = two; down = one)\n\n    new_lvl_up = min(level(up) + 1, 10)\n    new_pos_up =\n        clamp.(rand(model.rng, -1:1, 2) .+ space(up), [1, 1], size(model.space)[1:2])\n    move_agent!(up, (new_pos_up..., new_lvl_up), model)\n    new_lvl_down = level(down) - 1\n    if new_lvl_down == 0\n        kill_agent!(down, model)\n    else\n        move_agent!(down, (space(down)..., new_lvl_down), model)\n    end\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"If an agent has a prisoner, it will taunt it for a time, then kill it, so long as an opportunist doesn't sneak up on them first! Here we use the tuple constructor with nearby_ids to look for agents at the same position as the captor (0, 0), and any level (..., 10). We could also use the range constructor in this instance nearby_ids(agent, model, [(1, 0:0), (2, 0:0)]), meaning which is more performant but not as readable.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function captor_behavior!(agent, model)\n    close_ids = collect(nearby_ids(agent, model, (0, 0, 10)))\n    if length(close_ids) == 1\n        # Taunt prisoner or kill it\n        prisoner = model[close_ids[1]]\n        if prisoner.capture_time > 10\n            agent.shape = :rect\n            gain = ceil(Int, level(prisoner) / 2)\n            new_lvl = min(level(agent) + gain, 10)\n            kill_agent!(prisoner, model)\n            agent.has_prisoner = false\n            move_agent!(agent, (space(agent)..., new_lvl), model)\n        end\n    else\n        # Someone is here to kill the captor. Could be more than one opponent\n        prisoner = [model[id] for id in close_ids if model[id].capture_time > 0][1]\n        exploiter = rand(\n            model.rng,\n            [\n                model[id]\n                for\n                id in close_ids if\n                model[id].capture_time == 0 && model[id].has_prisoner == false\n            ],\n        )\n        exploiter.shape = :rect\n        gain = ceil(Int, level(agent) / 2)\n        new_lvl = min(level(agent) + rand(model.rng, 1:gain), 10)\n        kill_agent!(agent, model)\n        move_agent!(exploiter, (space(exploiter)..., new_lvl), model)\n        # Prisoner runs away in the commotion\n        prisoner.shape = :utriangle\n        prisoner.capture_time = 0\n        walk!(prisoner, (rand(model.rng, -1:1, 2)..., 0), model)\n    end\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"When there are only few fighters standing, the stakes are higher. Prior experience is paramount since there is no gain, and fights are to the death.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function endgame!(agent, model)\n    origin = space(agent)\n    end_ids = collect(Iterators.filter(\n        id -> model[id].shape == :circle && id != agent.id,\n        allids(model),\n    ))\n    agent.shape = :circle\n    if !isempty(end_ids)\n        opponent = closest_target(agent, end_ids, model)\n        target = space(opponent)\n        if origin == target\n            # Battle\n            agent.shape = :rect\n            opponent.shape = :rect\n            showdown!(agent, opponent, model)\n        else\n            walk!(agent, (sign.(target .- origin)..., 0), model)\n        end\n    end\nend\n\nfunction showdown!(one::Fighter, two::Fighter, model)\n    if level(one) == level(two)\n        # Odds are equivalent\n        one_winner = rand(model.rng) < 0.5\n    elseif level(one) > level(two)\n        # Odds are in favor of one\n        one_winner = level(one) - level(two) * rand(model.rng) > rand(model.rng)\n    else\n        # Odds are in favor of two\n        one_winner = rand(model.rng) > level(two) - level(one) * rand(model.rng)\n    end\n\n    one_winner ? kill_agent!(two, model) : kill_agent!(one, model)\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The rest of our interactions flow down a hierarchy, so we'll place them directly in the agent_step! function. We use the tuple search for occupied_ids here, as we did with close_ids above. The rest of the searches however use the range search to provide a more precise criteria.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The easiest context to explore is worthy_ids: all we want to do is find an agent with a similar level. If we used the tuple search here, we would have to search (100, 100, 1) - even though we are not at all interested in the spatial location of the neighbors at this time. (3, -1:1) is therefore more accurate representation.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"A more complex example is that of strong_ids. We are looking for agents with a level 2-4 points higher withing a distance of (5, 5). The range search becomes a little verbose, but precise. An equivalent tuple search is not completely possible however. The closest solution is (5, 5, 4), which also looks for weaker opponents and must be filtered to the correct neighbor set after the fact. In this instance the range search has significant performance gains.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function agent_step!(agent, model)\n    if agent.capture_time > 0\n        # Captured agents are powerless, but we need to keep track of how long\n        # they have been in this state\n        agent.capture_time += 1\n    elseif agent.has_prisoner\n        captor_behavior!(agent, model)\n    else\n        origin = space(agent)\n        # Find agents that have captives, they are not focused\n        occupied_ids = collect(Iterators.filter(\n            id -> model[id].has_prisoner,\n            nearby_ids(agent, model, (7, 7, 10)),\n        ))\n        if !isempty(occupied_ids)\n            # Sneak up behind them\n            target = space(closest_target(agent, occupied_ids, model))\n            agent.shape = :pentagon\n            walk!(agent, (sign.(target .- origin)..., 0), model)\n        else\n            # Opponents that are greatly higher in rank that the current agent\n            strong_ids = collect(nearby_ids(agent, model, [(1, -5:5), (2, -5:5), (3, 2:4)]))\n            if !isempty(strong_ids)\n                # Run away from nearest\n                target = space(closest_target(agent, strong_ids, model))\n                agent.shape = :utriangle\n                walk!(agent, (sign.(origin .- target)..., 0), model)\n            else\n                # There are no distractions. Search for the closest worthy opponent\n                worthy_ids = collect(nearby_ids(agent, model, [(3, -1:1)]))\n                if !isempty(worthy_ids)\n                    opponent = closest_target(agent, worthy_ids, model)\n                    target = space(opponent)\n                    if origin == target\n                        # Battle\n                        agent.shape = :rect\n                        opponent.shape = :rect\n                        battle!(agent, opponent, model)\n                    else\n                        # Move towards worthy opponent\n                        agent.shape = :diamond\n                        walk!(agent, (sign.(target .- origin)..., 0), model)\n                    end\n                else\n                    # Find any weak targets in the vicinity\n                    weak_ids = collect(nearby_ids(\n                        agent,\n                        model,\n                        [(1, -10:10), (2, -10:10), (3, -4:-2)],\n                    ))\n                    if !isempty(weak_ids)\n                        prisoner = closest_target(agent, weak_ids, model)\n                        target = space(prisoner)\n                        if origin == target\n                            # Capture and taunt target\n                            agent.has_prisoner = true\n                            agent.shape = :vline\n                            prisoner.capture_time += 1\n                            prisoner.shape = :hline\n                        else\n                            # Chase down nearest (can move 2 steps at a time!)\n                            agent.shape = :star4\n                            walk!(agent, (2 .* sign.(target .- origin)..., 0), model)\n                        end\n                    else\n                        # Abandon honour. This is the end\n                        endgame!(agent, model)\n                    end\n                end\n            end\n        end\n    end\n\n    return nothing\nend","category":"page"},{"location":"examples/battle/#Let-the-Battle-Begin","page":"Battle Royale","title":"Let the Battle Begin","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Plotting is relatively straightforward. plotabm cannot be used explicitly (yet) since it expects our categorical dimension is actually a third spatial one. We start with some custom legends to easier understand the dynamics.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"label_action = [\"Battle\", \"Run\", \"Showdown\", \"Sneak\", \"Duel\", \"Captor\", \"Prisoner\", \"Chase\"]\nactions = [:rect, :utriangle, :circle, :pentagon, :diamond, :vline, :hline, :star4]\ngroup_action = [\n    MarkerElement(\n        marker = marker,\n        color = :black,\n        strokecolor = :transparent,\n        markersize = 15,\n    ) for marker in actions\n]\ngroup_level = [\n    PolyElement(color = color, strokecolor = :transparent) for color in cgrad(:tab10)[1:10]\n]\nnothing #hide","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"And some complex internals that will be hidden away in the near future","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"e = size(model.space.s)[1:2] .+ 2\no = zero.(e) .- 2\nclr(agent) = cgrad(:tab10)[level(agent)]\nmkr(a) = a.shape\ncolors = Observable(to_color.([clr(model[id]) for id in Schedulers.by_id(model)]))\nmarkers = Observable([mkr(model[id]) for id in Schedulers.by_id(model)])\npos = Observable([model[id].pos for id in Schedulers.by_id(model)])\nstepper = InteractiveDynamics.ABMStepper(\n    clr,\n    mkr,\n    15,\n    nothing,\n    Schedulers.by_id,\n    pos,\n    colors,\n    Observable(15),\n    markers,\n    nothing,\n    nothing\n)\nnothing #hide","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Finally, the plot:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"f = Figure(resolution = (600, 700))\nax = f[1, 1] = Axis(f, title = \"Battle Royale\")\nhidedecorations!(ax)\nax.xgridvisible = true\nax.ygridvisible = true\nf[2, 1] = Legend(\n    f,\n    [group_action, group_level],\n    [label_action, string.(1:10)],\n    [\"Action\", \"Level\"],\n    orientation = :horizontal,\n    tellheight = true,\n    tellwidth = false,\n    nbanks = 5,\n)\n\nscatter!(ax, pos; color = colors, markersize = 15, marker = markers, strokewidth = 0.0)\nxlims!(ax, o[1], e[1])\nylims!(ax, o[2], e[2])\nrecord(f, \"battle.mp4\", 0:225; framerate = 10) do i\n    Agents.step!(stepper, model, agent_step!, dummystep, 1)\nend\nnothing # hide","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../battle.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Some interesting behaviour emerges: sometimes you see a group of diamonds chasing one triangle. What ends up happening here is usually a close pair that wishes to fight gets caught out by the weaker one of the two running away from an even stronger opponent. Problem is that this stronger opponent is chasing the stronger of the pair, but since the weakest of the pair is still closer to the newcomer, there is a stalemate. This is usually resolved by hitting a boundary or other opponents.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"EditURL = \"https://github.com/JuliaDynamics/AgentsExampleZoo.jl/blob/master/docs/examples/wealth_distribution.jl\"","category":"page"},{"location":"examples/wealth_distribution/#Wealth-distribution-model","page":"Wealth distribution model","title":"Wealth distribution model","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"This model is a simple agent-based economy that is modelled according to the work of Dragulescu et al.. This work introduces statistical mechanics concepts to study wealth distributions. What we show here is also referred to as \"Boltzmann wealth distribution\" model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"This model has a version with and without space. The rules of the space-less game are quite simple:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"There is a pre-determined number of agents.\nAll agents start with one unit of wealth.\nAt every step an agent gives 1 unit of wealth (if they have it) to some other agent.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"Even though this rule-set is simple, it can still recreate the basic properties of wealth distributions, e.g. power-laws distributions.","category":"page"},{"location":"examples/wealth_distribution/#Core-structures:-space-less","page":"Wealth distribution model","title":"Core structures: space-less","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"We start by defining the Agent type and initializing the model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"using Agents\nusing Random # hide\nRandom.seed!(5) # hide\n\nmutable struct WealthAgent <: AbstractAgent\n    id::Int\n    wealth::Int\nend","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"Notice that this agent does not have a pos field. That is okay, because there is no space structure to this example. We can also make a very simple AgentBasedModel for our model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"function wealth_model(; numagents = 100, initwealth = 1)\n    model = ABM(WealthAgent, scheduler = Schedulers.randomly)\n    for i in 1:numagents\n        add_agent!(model, initwealth)\n    end\n    return model\nend\n\nmodel = wealth_model()","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"The next step is to define the agent step function","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"function agent_step!(agent, model)\n    agent.wealth == 0 && return # do nothing\n    ragent = random_agent(model)\n    agent.wealth -= 1\n    ragent.wealth += 1\nend\nnothing # hide","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"We use random_agent as a convenient way to just grab a second agent. (this may return the same agent as agent, but we don't care in the long run)","category":"page"},{"location":"examples/wealth_distribution/#Running-the-space-less-model","page":"Wealth distribution model","title":"Running the space-less model","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"Let's do some data collection, running a large model for a lot of time","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"N = 5\nM = 2000\nadata = [:wealth]\nmodel = wealth_model(numagents = M)\ndata, _ = run!(model, agent_step!, N; adata)\ndata[(end-20):end, :]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"What we mostly care about is the distribution of wealth, which we can obtain for example by doing the following query:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"wealths = filter(x -> x.step == N - 1, data)[!, :wealth]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"and then we can make a histogram of the result. With a simple visualization we immediately see the power-law distribution:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"using CairoMakie\nCairoMakie.activate!() # hide\nhist(\n    wealths;\n    bins = collect(0:9),\n    width = 1,\n    color = cgrad(:viridis)[28:28:256],\n    figure = (resolution = (600, 400),),\n)","category":"page"},{"location":"examples/wealth_distribution/#Core-structures:-with-space","page":"Wealth distribution model","title":"Core structures: with space","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"We now expand this model to (in this case) a 2D grid. The rules are the same but agents exchange wealth only with their neighbors.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"It is also available from the Models module as Models.wealth_distribution.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"We therefore have to add a pos field as the second field of the agents:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"mutable struct WealthInSpace <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Int}\n    wealth::Int\nend\n\nfunction wealth_model_2D(; dims = (25, 25), wealth = 1, M = 1000)\n    space = GridSpace(dims, periodic = true)\n    model = ABM(WealthInSpace, space; scheduler = Schedulers.randomly)\n    for i in 1:M # add agents in random positions\n        add_agent!(model, wealth)\n    end\n    return model\nend\n\nmodel2D = wealth_model_2D()","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"The agent actions are a just a bit more complicated in this example. Now the agents can only give wealth to agents that exist on the same or neighboring positions (their \"neighbors\").","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"function agent_step_2d!(agent, model)\n    agent.wealth == 0 && return # do nothing\n    neighboring_positions = collect(nearby_positions(agent.pos, model))\n    push!(neighboring_positions, agent.pos) # also consider current position\n    rpos = rand(model.rng, neighboring_positions) # the position that we will exchange with\n    available_ids = ids_in_position(rpos, model)\n    if length(available_ids) > 0\n        random_neighbor_agent = model[rand(model.rng, available_ids)]\n        agent.wealth -= 1\n        random_neighbor_agent.wealth += 1\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/wealth_distribution/#Running-the-model-with-space","page":"Wealth distribution model","title":"Running the model with space","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"init_wealth = 4\nmodel = wealth_model_2D(; wealth = init_wealth)\nadata = [:wealth, :pos]\ndata, _ = run!(model, agent_step_2d!, 10; adata = adata, when = [1, 5, 9])\ndata[(end-20):end, :]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"Okay, now we want to get the 2D spatial wealth distribution of the model. That is actually straightforward:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"function wealth_distr(data, model, n)\n    W = zeros(Int, size(model.space))\n    for row in eachrow(filter(r -> r.step == n, data)) # iterate over rows at a specific step\n        W[row.pos...] += row.wealth\n    end\n    return W\nend\n\nfunction make_heatmap(W)\n    figure = Figure(; resolution = (600, 450))\n    hmap_l = figure[1, 1] = Axis(figure)\n    hmap = heatmap!(hmap_l, W; colormap = cgrad(:default))\n    cbar = figure[1, 2] = Colorbar(figure, hmap; width = 30)\n    return figure\nend\n\nW1 = wealth_distr(data, model2D, 1)\nmake_heatmap(W1)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"W5 = wealth_distr(data, model2D, 5)\nmake_heatmap(W5)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"W10 = wealth_distr(data, model2D, 9)\nmake_heatmap(W10)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution model","title":"Wealth distribution model","text":"What we see is that wealth gets more and more localized.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: Agents.jl)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"note: This is an examples-only repository!\nPlease notice that this repository holds only examples of various models implemented in Agents.jl. To actually learn how to use Agents.jl please visit the online documentation first!","category":"page"},{"location":"#Overview-of-Examples","page":"Introduction","title":"Overview of Examples","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Our ever growing list of examples are designed to showcase what is possible with Agents.jl. Here, we outline a number of topics that new and advanced users alike can quickly reference to find exactly what they're looking for.","category":"page"},{"location":"#Discrete-spaces","page":"Introduction","title":"Discrete spaces","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Making a discrete grid is perhaps the easiest way to conceptualise space in a model. That is why the main example of Agents.jl documentation is the Schelling model on a discrete space. Sugarscape is one of our more complex examples, but gives you a good overview of what is possible on a grid. If you're looking for something simpler, then the Forest fire would be a good start, which is also an example of a cellular automaton. Daisyworld is a famous ABM example which has both agent and model dynamics, similarly with Sugarscape.","category":"page"},{"location":"#Continuous-spaces","page":"Introduction","title":"Continuous spaces","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"In this space, agents generally move with a given velocity and interact in a far smoother manner than grid based models.  The Flocking model is perhaps the most famous example of bottom-up emergent phenomena and is hosted in the main Agents.jl documentation. Something quite topical at present is our Continuous space social distancing example. Finally, an excellent and complex example of what can be done in a continuous space: Bacterial Growth.","category":"page"},{"location":"#Higher-dimensional-spaces","page":"Introduction","title":"Higher dimensional spaces","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Battle Royale is an advanced example which leverages a 3-dimensional grid space, but only uses 2 of those dimensions for space. The third represents an agent category. Here, we can leverage Agents.jl's sophisticated neighbor searches to find closely related agents not just in space, but also in property.","category":"page"},{"location":"#Agent-Path-finding","page":"Introduction","title":"Agent Path-finding","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Besides the main (and most complex) example we have in the docs with Rabbit, Fox, Hawk, here are two more models showcasing the possibilities of pathfinding: Maze Solver and Mountain Runners.","category":"page"},{"location":"#Synchronous-agent-updates","page":"Introduction","title":"Synchronous agent updates","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Most of the time, using the agent_step! loop then the model_step! is sufficient to evolve a model. What if there's a more complicated set of dynamics you need to employ? Take a look at the Hegselmann-Krause opinion dynamics: it shows us how to make a second agent loop within model_step! to synchronise changes across all agents after agent_step! dynamics have completed.","category":"page"},{"location":"#Agent-sampling","page":"Introduction","title":"Agent sampling","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Wright-Fisher model of evolution shows us how we can sample a population of agents based on certain model properties. This is quite helpful in genetic and biology studies where agents are cell analogues.","category":"page"},{"location":"#Cellular-Automata","page":"Introduction","title":"Cellular Automata","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"A subset of ABMs, these models have individual agents with a set of behaviors, interacting with neighboring cells and the world around them, but never moving. Some examples of this model type are Conway's game of life, Forest fire and Daisyworld.","category":"page"},{"location":"#Mixed-Models","page":"Introduction","title":"Mixed Models","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"In the real world, groups of people interact differently with people they know vs people they don't know. In ABM worlds, that's no different. Predator-prey dynamics (or more colloquially: Wolf-Sheep) implements interactions between a pack of Wolves, a heard of Sheep and meadows of Grass. Daisyworld is an example of how a model property (in this case temperature) can be elevated to an agent type.","category":"page"},{"location":"#Advanced-visualization","page":"Introduction","title":"Advanced visualization","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Sugarscape example shows how to animate, in parallel, one plot that shows the ABM evolution, and another plot that shows any quantity a user is interested in.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The Bacterial Growth example shows how to make customized shapes for your agents that change over time as the agents evolve.","category":"page"}]
}
